
<!DOCTYPE html>
<html lang="zh-tw">
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css">

    <script src="https://cdn.jsdelivr.net/npm/moment@2.29.1/min/moment.min.js"></script>
    
      <script src="https://cdn.jsdelivr.net/npm/moment@2.29.1/locale/zh-tw.js"></script>
    
    <script src="https://cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script>
    <script>
      window.algoliaConfig = {
        appId: 'AWFC86Q51O',
        apiKey: 'c9d952906eb1b154d75cf863e75c1ede',
        indexName: 'MyBlog'
      };
      var algoliaIndex = algoliasearch(
        algoliaConfig.appId,
        algoliaConfig.apiKey
      ).initIndex(algoliaConfig.indexName);
    </script>


<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Kein&#39;s blog">
    <title>所有文章: 2017/11 - Kein&#39;s blog</title>
    <meta name="author" content="Kein Chan">
    
    
    
    <script type="application/ld+json">{}</script>
    <meta property="og:type" content="blog">
<meta property="og:title" content="Kein&#39;s blog">
<meta property="og:url" content="https://chankein.github.io/archives/2017/11/index.html">
<meta property="og:site_name" content="Kein&#39;s blog">
<meta property="og:locale" content="zh_TW">
<meta property="article:author" content="Kein Chan">
<meta name="twitter:card" content="summary">
    
    
        
    
    
        <meta property="og:image" content="https://chankein.github.io../../../assets/images/profile.jpg"/>
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="../../../assets/css/style-l9zwheso7r7pnk98nvirovsz9dl7fhkrc9mlb5vmuxw7tk5movrk0eevsrpr.min.css">

    <!--STYLES END-->
    

    

    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="1">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="../../../index.html"
            aria-label=""
        >
            Kein&#39;s blog
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="打開鏈接: ../../../#about"
            >
        
        
            <img class="header-picture" src="../../../assets/images/profile.jpg" alt="作者的圖片"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="1">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="../../../#about"
                    aria-label="閱讀有關作者的更多信息"
                >
                    <img class="sidebar-profile-picture" src="../../../assets/images/profile.jpg" alt="作者的圖片"/>
                </a>
                <h4 class="sidebar-profile-name">Kein Chan</h4>
                
                    <h5 class="sidebar-profile-bio"><p>這是獨立全棧工程師Kein Chan的技術博客</br>分享一些技術教程,命令備忘(cheat-sheet)等</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="../../../index.html"
                            
                            rel="noopener"
                            title="首頁"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">首頁</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="../../../all-categories"
                            
                            rel="noopener"
                            title="分類"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">分類</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="../../../all-tags"
                            
                            rel="noopener"
                            title="標籤"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">標籤</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="../../../all-archives"
                            
                            rel="noopener"
                            title="所有文章"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">所有文章</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link open-algolia-search"
                            href="#search"
                            
                            rel="noopener"
                            title="搜尋"
                        >
                        <i class="sidebar-button-icon fa fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">搜尋</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="關於"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">關於</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/chankein/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://www.linkedin.com/profile/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="LinkedIn"
                        >
                        <i class="sidebar-button-icon fab fa-linkedin" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">LinkedIn</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="../../../mailto:kein.chan85@gmail.com"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Email"
                        >
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Email</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="../../../atom.xml"
                            
                            rel="noopener"
                            title="Atom"
                        >
                        <i class="sidebar-button-icon fa fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Atom</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="1"
                 class="
                        hasCoverMetaIn
                        ">
                
    <section class="postShorten-group main-content-wrap">
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="../../../2017/11/30/database/%E6%90%AD%E5%BB%BA%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8FKafka%E5%88%86%E5%B8%83%E5%BC%8F%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%B6%88%E6%81%AF%E9%9B%86%E7%BE%A4/"
                            aria-label=": 搭建高吞吐量Kafka分布式发布订阅消息集群"
                        >
                            搭建高吞吐量Kafka分布式发布订阅消息集群
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2017-11-30T23:14:37+08:00">
	
		    2017 年 11 月 30 日
    	
    </time>
    
        <span>分類 </span>
        
    <a class="category-link" href="../../../categories/database/">database</a>, <a class="category-link" href="../../../categories/database/hadoop/">hadoop</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h2 id="搭建高吞吐量-Kafka-分布式发布订阅消息-集群">搭建高吞吐量 Kafka 分布式发布订阅消息 集群</h2>
<h3 id="简介">简介</h3>
<p>Kafka 是一种高吞吐的分布式发布订阅消息系统，能够替代传统的消息队列用于解耦合数据处理，缓存未处理消息等，同时具有更高的吞吐率，支持分区、多副本、冗余，因此被广泛用于大规模消息数据处理应用。Kafka 支持Java 及多种其它语言客户端，可与Hadoop、Storm、Spark等其它大数据工具结合使用。</p>
<h3 id="环境">环境</h3>
<p>Zookeeper集群: 192.168.252.121:2181,192.168.252.122:2181,192.168.252.123:2181</p>
<p>kafka 集群: 192.168.252.124 , 192.168.252.125 , 192.168.252.126</p>
<p>kafka-manager: 192.168.252.127</p>
<h4 id="主机名修改">主机名修改</h4>
<p>CentOs7.3 修改主机名</p>
<h4 id="ssh-免密登录">ssh 免密登录</h4>
<p>CentOs7.3 ssh 免密登录</p>
<h4 id="安装-JDK1-8">安装 JDK1.8</h4>
<p><a href="https://chankein.github.io/2018/01/07/java/CentOs7-3-%E5%AE%89%E8%A3%85-JDK1-8/">CentOs7.3 安装 JDK1.8</a></p>
<h4 id="搭建-Zookeeper-集群">搭建 Zookeeper 集群</h4>
<p><a href="https://chankein.github.io/2017/11/27/database/CentOs7-3%E6%90%AD%E5%BB%BAZooKeeper-3-4-9Cluster-%E9%9B%86%E7%BE%A4%E6%9C%8D%E5%8A%A1/">CentOs7.3 搭建 ZooKeeper-3.4.9 Cluster 集群服务</a></p>
<p>Zookeeper集群: 192.168.252.121:2181,192.168.252.122:2181,192.168.252.123:2181</p>
<p>主机名依次被我修改成: <strong>node1,node2,node3</strong></p>
<h3 id="搭建-kafka-集群">搭建 kafka 集群</h3>
<p>kafka 集群: 192.168.252.124 , 192.168.252.125 , 192.168.252.126</p>
<p>主机名依次被我修改成: <strong>node4,node5,node6</strong></p>
<h4 id="1-下载代码">1.下载代码</h4>
<p><a target="_blank" rel="noopener" href="https://kafka.apache.org/downloads">kafka 官网下载 http://kafka.apache.org/downloads</a></p>
<p>下载最新版本的kafka ，</p>
<p>清华镜像:<a target="_blank" rel="noopener" href="https://mirrors.tuna.tsinghua.edu.cn/apache/kafka/">https://mirrors.tuna.tsinghua.edu.cn/apache/kafka/</a></p>
<p>阿里镜像:<a target="_blank" rel="noopener" href="https://mirrors.aliyun.com/apache/kafka/">https://mirrors.aliyun.com/apache/kafka/</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ cd /opt</span><br><span class="line">$ wget https://mirrors.tuna.tsinghua.edu.cn/apache/kafka/0.11.0.0/kafka_2.12-0.11.0.0.tgz</span><br><span class="line">$ tar -zxvf kafka_2.12-0.11.0.0.tgz</span><br><span class="line">$ cd kafka_2.12-0.11.0.0</span><br></pre></td></tr></table></figure>
<h4 id="2-修改配置">2.修改配置</h4>
<p>在 node4 操作</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vi /opt/kafka_2.12-0.11.0.0/config/server.properties</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">broker.id=0  每台服务器不能重复</span><br><span class="line"></span><br><span class="line">#设置zookeeper的集群地址</span><br><span class="line">zookeeper.connect=192.168.252.121:2181,192.168.252.122:2181,192.168.252.123:2181</span><br></pre></td></tr></table></figure>
<p>把配置复制到 node5,node6 集群</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ for a in &#123;5..6&#125; ; do scp -r /opt/kafka_2.12-0.11.0.0/ node$a:/opt/kafka_2.12-0.11.0.0 ; done</span><br></pre></td></tr></table></figure>
<p>修改 node5,node6 集群的<code>broker.id</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vi /opt/kafka_2.12-0.11.0.0/config/server.properties</span><br></pre></td></tr></table></figure>
<h4 id="3-启动kafka">3.启动kafka</h4>
<p>在 node1,启动 Kafka使用的 ZooKeeper，所以先<strong>启动ZooKeeper服务器</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ for a in &#123;1..3&#125; ; do ssh node$a &quot;source /etc/profile;  /opt/zookeeper-3.4.9/bin/zkServer.sh start&quot; ; done</span><br></pre></td></tr></table></figure>
<p><strong>现在 node4 启动Kafka服务器</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ for a in &#123;4..6&#125; ; do ssh node$a &quot;source /etc/profile;  /opt/kafka_2.12-0.11.0.0/bin/kafka-server-start.sh /opt/kafka_2.12-0.11.0.0/config/server.properties&quot; ; done</span><br></pre></td></tr></table></figure>
<p>或者后台启动运行，日志查看去Kafka解压目录有个<code>log</code> 文件夹查看</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ for a in &#123;4..6&#125; ; do ssh node$a &quot;source /etc/profile; nohup  /opt/kafka_2.12-0.11.0.0/bin/kafka-server-start.sh /opt/kafka_2.12-0.11.0.0/config/server.properties &gt; /dev/null 2&gt;&amp;1 &amp;&quot; ; done</span><br></pre></td></tr></table></figure>
<p>查看进程，Kafka 是否启动成功</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ jps</span><br><span class="line">3825 Kafka</span><br><span class="line">6360 Jps</span><br></pre></td></tr></table></figure>
<p>如果报错删除</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.</span><br><span class="line"></span><br><span class="line">$ rm -rf /tmp/kafka-logs</span><br></pre></td></tr></table></figure>
<h4 id="4-创建主题">4.创建主题</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ /opt/kafka_2.12-0.11.0.0/bin/kafka-topics.sh --create --zookeeper 192.168.252.121:2181,192.168.252.122:2181,192.168.252.123:2181 --replication-factor 2 --partitions 1 --topic ymq</span><br></pre></td></tr></table></figure>
<p>--replication-factor 2 #复制两份<br>
--partitions 1 #创建1个分区<br>
--topic #主题为ymq</p>
<p>运行list topic命令，可以看到该主题：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ /opt/kafka_2.12-0.11.0.0/bin/kafka-topics.sh --list --zookeeper 192.168.252.121:2181,192.168.252.122:2181,192.168.252.123:2181</span><br></pre></td></tr></table></figure>
<h4 id="5-生产消息">5.生产消息</h4>
<p>Kafka附带一个命令行客户端，它将从文件或标准输入中输入，并将其作为消息发送到Kafka群集。默认情况下，每行将作为单独的消息发送。</p>
<p>在 <strong>node5</strong> 运行生产者，然后在控制台中输入一些消息以发送到服务器。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ /opt/kafka_2.12-0.11.0.0/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic ymq</span><br><span class="line">&gt;www.ymq.io</span><br></pre></td></tr></table></figure>
<h4 id="6-消费消息">6.消费消息</h4>
<p>在<strong>node6</strong> 运行消费者，将把消息转储到标准输出。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ /opt/kafka_2.12-0.11.0.0/bin/kafka-console-consumer.sh --zookeeper 192.168.252.121:2181,192.168.252.122:2181,192.168.252.123:2181  --topic ymq --from-beginning</span><br><span class="line">Using the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper]. </span><br><span class="line">www.ymq.io</span><br></pre></td></tr></table></figure>
<h4 id="7-topic详情">7.topic详情</h4>
<p>用describe 查看集群中topic每个节点情况</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ /opt/kafka_2.12-0.11.0.0/bin/kafka-topics.sh --describe --zookeeper 192.168.252.121:2181,192.168.252.122:2181,192.168.252.123:2181 --topic ymq</span><br><span class="line">Topic:ymq    PartitionCount:1    ReplicationFactor:2    Configs:</span><br><span class="line">    Topic: ymq    Partition: 0    Leader: 1    Replicas: 1,3    Isr: 3,1</span><br></pre></td></tr></table></figure>
<p>以下是输出的说明。第一行给出了所有分区的摘要，每个附加行提供有关一个分区的信息。由于我们这个主题只有一个分区，只有一行。</p>
<p><code>leader</code>负责给定分区的读取和写入分配节点编号，每个分区的部分数据会随机指定不同的节点<br>
<code>replicas</code>是复制此分区的日志的节点列表<br>
<code>isr</code>一组正在同步的副本列表</p>
<h4 id="8-删除topic">8.删除topic</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ /opt/kafka_2.12-0.11.0.0/bin/kafka-topics.sh --delete --zookeeper 192.168.252.121:2181,192.168.252.122:2181,192.168.252.123:2181 --topic ymq</span><br><span class="line">Topic ymq is marked for deletion.</span><br><span class="line">Note: This will have no impact if delete.topic.enable is not set to true.</span><br></pre></td></tr></table></figure>
<h4 id="9-停止kafka">9.停止kafka</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ for a in &#123;4..6&#125; ; do ssh node$a &quot;source /etc/profile;  /opt/kafka_2.12-0.11.0.0/bin/kafka-server-stop.sh /opt/kafka_2.12-0.11.0.0/config/server.properties &quot; ; done</span><br></pre></td></tr></table></figure>
<h3 id="部署-Kafka-Manager">部署 Kafka Manager</h3>
<p><a target="_blank" rel="noopener" href="https://github.com/yahoo/CMAK">Yahoo开源Kafka集群管理器Kafka Manager</a></p>
<p>作为一个分布式的消息发布-订阅系统，Apache Kafka在Yahoo内部已经被很多团队所使用，例如媒体分析团队就将其应用到了实时分析流水线中，同时，Yahoo整个Kafka集群处理的峰值带宽超过了20Gbps（压缩数据）。为了让开发者和服务工程师能够更加简单地维护Kafka集群，Yahoo构建了一个基于Web的管理工具，称为Kafka Manager，日前该项目已经在GitHub上开源。</p>
<p>通过Kafka Manager用户能够更容易地发现集群中哪些主题或者分区分布不均匀，同时能够管理多个集群，能够更容易地检查集群的状态，能够创建主题，执行首选的副本选择，能够基于集群当前的状态生成分区分配，并基于生成的分配执行分区的重分配，此外，Kafka Manager还是一个非常好的可以快速查看集群状态的工具。</p>
<p>Kafka Manager使用Scala语言编写，其Web控制台基于Play Framework实现，除此之外，Yahoo还迁移了一些Apache Kafka的帮助程序以便能够与Apache Curator框架一起工作。</p>
<p>一、它支持以下内容：</p>
<ul>
<li>管理多个群集</li>
<li>容易检查集群状态（主题，消费者，偏移量，经纪人，副本分发，分区分配）</li>
<li>运行首选副本选举</li>
<li>使用选项生成分区分配，以选择要使用的代理</li>
<li>运行分区的重新分配（基于生成的分配）</li>
<li>创建可选主题配置的主题（0.8.1.1具有不同于0.8.2+的配置）</li>
<li>删除主题（仅支持0.8.2+，并记住在代理配​​置中设置delete.topic.enable = true）</li>
<li>主题列表现在表示标记为删除的主题（仅支持0.8.2+）</li>
<li>批量生成多个主题的分区分配，并选择要使用的代理</li>
<li>批量运行多个主题的分区重新分配</li>
<li>将分区添加到现有主题</li>
<li>更新现有主题的配置</li>
<li>可选地，启用JMX轮询代理级和主题级度量。</li>
<li>可选地筛选出在zookeeper中没有ids / owner /＆offset /目录的消费者。</li>
</ul>
<h4 id="源码，并编译打包">源码，并编译打包</h4>
<p>在 kafka-manager: 192.168.252.127 <strong>node7</strong> 部署</p>
<p><strong>编译超级慢</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ yum install git</span><br><span class="line">$ cd /opt/</span><br><span class="line">$ git clone https://github.com/yahoo/kafka-manager</span><br><span class="line">$ cd kafka-manager/</span><br><span class="line">$ ./sbt clean dist</span><br></pre></td></tr></table></figure>
<h4 id="下载编译好的包">下载编译好的包</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ yum install unzip</span><br><span class="line">$ unzip kafka-manager-1.3.2.1.zip</span><br><span class="line">$ vi /opt/kafka-manager-1.3.2.1/conf/application.conf</span><br></pre></td></tr></table></figure>
<p>修改这个 zk 地址</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-manager.zkhosts=&quot;192.168.252.121:2181,192.168.252.122:2181,192.168.252.123:2181&quot;</span><br></pre></td></tr></table></figure>
<h4 id="启动-kafka-manager">启动 kafka-manager</h4>
<p>默认端口 <code>NettyServer - Listening for HTTP on /0:0:0:0:0:0:0:0:9000</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ /opt/kafka-manager-1.3.2.1/bin/kafka-manager -Dconfig.file=conf/application.conf</span><br></pre></td></tr></table></figure>
<p>或者后台运行 并且配置端口</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nohup bin/kafka-manager  -Dconfig.file=/home/hadoop/app/kafka-manager-1.3.2.1/conf/application.conf -Dhttp.port=9000 &amp;</span><br></pre></td></tr></table></figure>
<p>访问： <a target="_blank" rel="noopener" href="http://ip:9000">http://ip:9000</a></p>
<p><img src="/assets/images/kafka.webp" alt="图片描述" title="图片描述"></p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="../../../2017/11/30/database/%E6%90%AD%E5%BB%BA%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8FKafka%E5%88%86%E5%B8%83%E5%BC%8F%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%B6%88%E6%81%AF%E9%9B%86%E7%BE%A4/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                留言與分享
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="../../../2017/11/27/database/CentOs7-3%E6%90%AD%E5%BB%BAZooKeeper-3-4-9Cluster-%E9%9B%86%E7%BE%A4%E6%9C%8D%E5%8A%A1/"
                            aria-label=": CentOs7.3搭建ZooKeeper-3.4.9Cluster 集群服务"
                        >
                            CentOs7.3搭建ZooKeeper-3.4.9Cluster 集群服务
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2017-11-27T23:08:40+08:00">
	
		    2017 年 11 月 27 日
    	
    </time>
    
        <span>分類 </span>
        
    <a class="category-link" href="../../../categories/database/">database</a>, <a class="category-link" href="../../../categories/database/hadoop/">hadoop</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h2 id="CentOs7-3-搭建-ZooKeeper-3-4-9-Cluster-集群服务">CentOs7.3 搭建 ZooKeeper-3.4.9 Cluster 集群服务</h2>
<h2 id="Zookeeper-概述">Zookeeper 概述</h2>
<p>zookeeper实际上是yahoo开发的，用于分布式中<strong>一致性处理的框架</strong>。最初其作为研发Hadoop时的副产品。由于分布式系统中一致性处理较为困难，其他的分布式系统没有必要 费劲重复造轮子，故随后的分布式系统中大量应用了zookeeper，以至于zookeeper成为了各种分布式系统的基础组件，其地位之重要，可想而知。著名的<strong>hadoop，kafka，dubbo 都是基于zookeeper而构建</strong>。</p>
<p>要想理解zookeeper到底是做啥的，那首先得理解清楚，<strong>什么是一致性？</strong></p>
<p>所谓的一致性，实际上就是围绕着“看见”来的。谁能看见？能否看见？什么时候看见？举个例子：淘宝后台卖家，在后台上架一件大促的商品，通过服务器A提交到主数据库，假设刚提交后立马就有用户去通过应用服务器B去从数据库查询该商品，就会出现一个现象，卖家已经更新成功了，然而买家却看不到；而经过一段时间后，主数据库的数据同步到了从数据库，买家就能查到了。</p>
<p>假设卖家更新成功之后买家立马就能看到卖家的更新，则称为<strong>强一致性</strong></p>
<p>如果卖家更新成功后买家不能看到卖家更新的内容，则称为<strong>弱一致性</strong></p>
<p>而卖家更新成功后，买家经过一段时间最终能看到卖家的更新，则称为<strong>最终一致性</strong></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/leesf456/p/6001278.html">《一致性协议》</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/leesf456/p/6036548.html">《ZooKeeper应用场景》</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/leesf456/p/5992377.html">《分布式架构》</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/leesf456/tag/%E5%88%86%E5%B8%83%E5%BC%8F/">《分布式 ZooKeeper 系列》</a></p>
<h2 id="环境">环境</h2>
<p>VMware版本号：12.0.0</p>
<p>CentOS版本：CentOS 7.3.1611</p>
<p>ZooKeeper版本：ZooKeeper-3.4.9.tar.gz</p>
<p>虚拟机IP：192.168.252.101，192.168.252.102，192.168.252.103</p>
<p>集群主机名称：node1，node2，node3</p>
<p>集群主机用户：都是用root用户</p>
<p>集群JDK环境：jdk-8u144-linux-x64.tar.gz JDK 1.8 安装 具体参考<a href="https://chankein.github.io/2018/01/07/java/CentOs7-3-%E5%AE%89%E8%A3%85-JDK1-8/">《CentOs7.3 安装 JDK1.8》</a></p>
<p>集群主机之间设置免密登陆：</p>
<h3 id="注意事项">注意事项</h3>
<p>关闭防火墙</p>
<p>centos 6.x 关闭 iptables</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ service iptables stop # 关闭命令：</span><br></pre></td></tr></table></figure>
<p>centos 7.x 关闭firewall</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl stop firewalld.service # 停止firewall</span><br></pre></td></tr></table></figure>
<h2 id="ZooKeeper-安装">ZooKeeper 安装</h2>
<h3 id="1-下载ZooKeeper">1.下载ZooKeeper</h3>
<p>下载最新版本的ZooKeeper ，我在北京我就选择，清华镜像比较快</p>
<p>清华镜像:<a target="_blank" rel="noopener" href="https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/">https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/</a></p>
<p>阿里镜像:<a target="_blank" rel="noopener" href="https://mirrors.aliyun.com/apache/zookeeper/">https://mirrors.aliyun.com/apache/zookeeper/</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cd /opt/</span><br><span class="line">$ wget https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.4.9/zookeeper-3.4.9.tar.gz</span><br></pre></td></tr></table></figure>
<p>或者在浏览器下载上传至opt 目录</p>
<h3 id="2-提取tar文件">2.提取tar文件</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ cd /opt/</span><br><span class="line">$ tar -zxf  zookeeper-3.4.9.tar.gz</span><br><span class="line">$ cd zookeeper-3.4.9</span><br></pre></td></tr></table></figure>
<p>创建<code>data</code>文件夹 用于存储数据文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir /opt/zookeeper-3.4.9/data</span><br></pre></td></tr></table></figure>
<p>创建<code>logs</code>文件夹 用于存储日志</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir /opt/zookeeper-3.4.9/logs  </span><br></pre></td></tr></table></figure>
<h3 id="3-创建配置文件">3.创建配置文件</h3>
<p><strong>zoo.cfg</strong></p>
<p>zookeeper的主要配置文件，因为Zookeeper是一个集群服务，集群的每个节点都需要这个配置文件。为了避免出差错，zoo.cfg这个配置文件里没有跟特定节点相关的配置，所以每个节点上的这个zoo.cfg都是一模一样的配置。这样就非常便于管理了，比如我们可以把这个文件提交到版本控制里管理起来。其实这给我们设计集群系统的时候也是个提示：集群系统一般有很多配置，应该尽量将通用的配置和特定每个服务的配置(比如服务标识)分离，这样通用的配置在不同服务之间copy就ok了</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vi /opt/zookeeper-3.4.9/conf/zoo.cfg</span><br></pre></td></tr></table></figure>
<p>编辑内容如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tickTime = 2000</span><br><span class="line">dataDir =  /opt/zookeeper-3.4.9/data</span><br><span class="line">dataLogDir = /opt/zookeeper-3.4.9/logs</span><br><span class="line">tickTime = 2000</span><br><span class="line">clientPort = 2181</span><br><span class="line">initLimit = 5</span><br><span class="line">syncLimit = 2</span><br><span class="line"></span><br><span class="line">server.1=node1:2888:3888</span><br><span class="line">server.2=node2:2888:3888</span><br><span class="line">server.3=node3:2888:3888</span><br></pre></td></tr></table></figure>
<h4 id="配置文件描述">配置文件描述</h4>
<p><strong>tickTime</strong></p>
<ul>
<li>tickTime则是上述两个超时配置的基本单位，例如对于initLimit，其配置值为5，说明其超时时间为 2000ms * 5 = 10秒。</li>
</ul>
<p><strong>dataDir</strong></p>
<ul>
<li>其配置的含义跟单机模式下的含义类似，不同的是集群模式下还有一个myid文件。myid文件的内容只有一行，且内容只能为1 - 255之间的数字，这个数字亦即上面介绍server.id中的id，表示zk进程的id。</li>
</ul>
<p><strong>dataLogDir</strong></p>
<ul>
<li>如果没提供的话使用的则是dataDir。zookeeper的持久化都存储在这两个目录里。dataLogDir里是放到的顺序日志(WAL)。而dataDir里放的是内存数据结构的snapshot，便于快速恢复。为了达到性能最大化，一般建议把dataDir和dataLogDir分到不同的磁盘上，这样就可以充分利用磁盘顺序写的特性。</li>
</ul>
<p><strong>initLimit</strong></p>
<ul>
<li>ZooKeeper集群模式下包含多个zk进程，其中一个进程为leader，余下的进程为follower。</li>
</ul>
<p>当follower最初与leader建立连接时，它们之间会传输相当多的数据，尤其是follower的数据落后leader很多。initLimit配置follower与leader之间建立连接后进行同步的最长时间。</p>
<p><strong>syncLimit</strong></p>
<ul>
<li>配置follower和leader之间发送消息，请求和应答的最大时间长度。</li>
</ul>
<p><strong>server.id=host:port1:port2</strong></p>
<p><code>server.id</code> 其中id为一个数字，表示zk进程的id，这个id也是data目录下myid文件的内容</p>
<p><code>host</code> 是该zk进程所在的IP地址</p>
<p><code>port1</code> 表示follower和leader交换消息所使用的端口</p>
<p><code>port2</code> 表示选举leader所使用的端口</p>
<h3 id="4-创建myid-文件">4.创建myid 文件</h3>
<p>在data里会放置一个myid文件，里面就一个数字，用来唯一标识这个服务。这个id是很重要的，一定要保证整个集群中唯一</p>
<p>ZooKeeper会根据这个id来取出server.x上的配置。比如当前id为1，则对应着zoo.cfg里的server.1的配置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ echo &quot;1&quot; &gt; /opt/zookeeper-3.4.9/data/myid</span><br></pre></td></tr></table></figure>
<p>这样一台node1机器就配置完了</p>
<h3 id="5-复制集群配置">5.复制集群配置</h3>
<p>在集群node1 上执行,复制配置好的zookeeper到其他两台主机上</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ for a in &#123;2..3&#125; ; do scp -r /opt/zookeeper-3.4.9/ node$a:/opt/zookeeper-3.4.9 ; done</span><br></pre></td></tr></table></figure>
<p>在集群node1 上执行 ,批量修改myid 文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ for a in &#123;1..3&#125; ; do ssh node$a &quot;source /etc/profile; echo $a &gt; /opt/zookeeper-3.4.9/data/myid&quot; ; done</span><br></pre></td></tr></table></figure>
<h2 id="集群操作">集群操作</h2>
<p><strong>在集群任意一台机器上执行</strong></p>
<h3 id="启动集群">启动集群</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ for a in &#123;1..3&#125; ; do ssh node$a &quot;source /etc/profile; /opt/zookeeper-3.4.9/bin/zkServer.sh start&quot; ; done</span><br></pre></td></tr></table></figure>
<p>响应</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper-3.4.9/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper-3.4.9/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper-3.4.9/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br></pre></td></tr></table></figure>
<h3 id="连接集群">连接集群</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ /opt/zookeeper-3.4.9/bin/zkCli.sh -server node1:2181,node2:2181,node3:2181</span><br></pre></td></tr></table></figure>
<p>响应</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Connecting to node1:2181,node2:2181,node3:2181</span><br><span class="line">2017-08-23 11:08:10,323 [myid:] - INFO  [main:Environment@100] - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT</span><br><span class="line">2017-08-23 11:08:10,328 [myid:] - INFO  [main:Environment@100] - Client environment:host.name=node1</span><br><span class="line">2017-08-23 11:08:10,329 [myid:] - INFO  [main:Environment@100] - Client environment:java.version=1.8.0_144</span><br><span class="line">2017-08-23 11:08:10,331 [myid:] - INFO  [main:Environment@100] - Client environment:java.vendor=Oracle Corporation</span><br><span class="line">2017-08-23 11:08:10,331 [myid:] - INFO  [main:Environment@100] - Client environment:java.home=/usr/lib/jvm/jre</span><br><span class="line">2017-08-23 11:08:10,331 [myid:] - INFO  [main:Environment@100] - Client environment:java.class.path=/opt/zookeeper-3.4.9/bin/../build/classes:/opt/zookeeper-3.4.9/bin/../build/lib/*.jar:/opt/zookeeper-3.4.9/bin/../lib/slf4j-log4j12-1.6.1.jar:/opt/zookeeper-3.4.9/bin/../lib/slf4j-api-1.6.1.jar:/opt/zookeeper-3.4.9/bin/../lib/netty-3.10.5.Final.jar:/opt/zookeeper-3.4.9/bin/../lib/log4j-1.2.16.jar:/opt/zookeeper-3.4.9/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.9/bin/../zookeeper-3.4.9.jar:/opt/zookeeper-3.4.9/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.9/bin/../conf:.:/lib/jvm/lib:/lib/jvm/jre/lib</span><br><span class="line">2017-08-23 11:08:10,331 [myid:] - INFO  [main:Environment@100] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib</span><br><span class="line">2017-08-23 11:08:10,331 [myid:] - INFO  [main:Environment@100] - Client environment:java.io.tmpdir=/tmp</span><br><span class="line">2017-08-23 11:08:10,331 [myid:] - INFO  [main:Environment@100] - Client environment:java.compiler=&lt;NA&gt;</span><br><span class="line">2017-08-23 11:08:10,331 [myid:] - INFO  [main:Environment@100] - Client environment:os.name=Linux</span><br><span class="line">2017-08-23 11:08:10,331 [myid:] - INFO  [main:Environment@100] - Client environment:os.arch=amd64</span><br><span class="line">2017-08-23 11:08:10,331 [myid:] - INFO  [main:Environment@100] - Client environment:os.version=3.10.0-514.26.2.el7.x86_64</span><br><span class="line">2017-08-23 11:08:10,331 [myid:] - INFO  [main:Environment@100] - Client environment:user.name=root</span><br><span class="line">2017-08-23 11:08:10,332 [myid:] - INFO  [main:Environment@100] - Client environment:user.home=/root</span><br><span class="line">2017-08-23 11:08:10,332 [myid:] - INFO  [main:Environment@100] - Client environment:user.dir=/root</span><br><span class="line">2017-08-23 11:08:10,333 [myid:] - INFO  [main:ZooKeeper@438] - Initiating client connection, connectString=node1:2181,node2:2181,node3:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@506c589e</span><br><span class="line">2017-08-23 11:08:10,361 [myid:] - INFO  [main-SendThread(node3:2181):ClientCnxn$SendThread@1032] - Opening socket connection to server node3/192.168.252.123:2181. Will not attempt to authenticate using SASL (unknown error)</span><br><span class="line">Welcome to ZooKeeper!</span><br><span class="line">JLine support is enabled</span><br><span class="line">2017-08-23 11:08:10,474 [myid:] - INFO  [main-SendThread(node3:2181):ClientCnxn$SendThread@876] - Socket connection established to node3/192.168.252.123:2181, initiating session</span><br><span class="line">[zk: node1:2181,node2:2181,node3:2181(CONNECTING) 0] 2017-08-23 11:08:10,535 [myid:] - INFO  [main-SendThread(node3:2181):ClientCnxn$SendThread@1299] - Session establishment complete on server node3/192.168.252.123:2181, sessionid = 0x35e0d0716340000, negotiated timeout = 30000</span><br><span class="line"></span><br><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line">WatchedEvent state:SyncConnected type:None path:null</span><br><span class="line"></span><br><span class="line">[zk: node1:2181,node2:2181,node3:2181(CONNECTED) 0]</span><br></pre></td></tr></table></figure>
<p>从日志可以看出客户端成功连接的是node3 连接上哪台机器的zk进程是随机的</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">2017-08-23 11:08:10,361 [myid:] - INFO  [main-SendThread(node3:2181):ClientCnxn$SendThread@1032] - Opening socket connection to server node3/192.168.252.123:2181. Will not attempt to authenticate using SASL (unknown error)</span><br><span class="line">Welcome to ZooKeeper!</span><br><span class="line">JLine support is enabled</span><br></pre></td></tr></table></figure>
<h3 id="集群状态">集群状态</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ for a in &#123;1..3&#125; ; do ssh node$a &quot;source /etc/profile; /opt/zookeeper-3.4.9/bin/zkServer.sh status&quot; ; done</span><br></pre></td></tr></table></figure>
<p>响应</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper-3.4.9/bin/../conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper-3.4.9/bin/../conf/zoo.cfg</span><br><span class="line">Mode: leader</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper-3.4.9/bin/../conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br></pre></td></tr></table></figure>
<p>通过日志我可以看到 node2 leader (ps 是老大)，其他 node1 ,node2 follower (ps 都是小弟)</p>
<p>Leader 怎么选举的可以参考<a target="_blank" rel="noopener" href="https://www.cnblogs.com/leesf456/p/6107600.html">《Zookeeper的Leader选举》</a></p>
<h3 id="停止集群">停止集群</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ for a in &#123;1..3&#125; ; do ssh node$a &quot;source /etc/profile; /opt/zookeeper-3.4.9/bin/zkServer.sh stop&quot; ; done</span><br></pre></td></tr></table></figure>
<p>响应</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper-3.4.9/bin/../conf/zoo.cfg</span><br><span class="line">Stopping zookeeper ... STOPPED</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper-3.4.9/bin/../conf/zoo.cfg</span><br><span class="line">Stopping zookeeper ... STOPPED</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper-3.4.9/bin/../conf/zoo.cfg</span><br><span class="line">Stopping zookeeper ... STOPPED</span><br></pre></td></tr></table></figure>

                    
                        


                    
                    
                        <p>
                            <a
                                href="../../../2017/11/27/database/CentOs7-3%E6%90%AD%E5%BB%BAZooKeeper-3-4-9Cluster-%E9%9B%86%E7%BE%A4%E6%9C%8D%E5%8A%A1/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                留言與分享
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="../../../2017/11/25/database/Hive-2-3-0-%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8/"
                            aria-label=": Hive-2.3.0 快速搭建与使用"
                        >
                            Hive-2.3.0 快速搭建与使用
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2017-11-25T14:09:42+08:00">
	
		    2017 年 11 月 25 日
    	
    </time>
    
        <span>分類 </span>
        
    <a class="category-link" href="../../../categories/database/">database</a>, <a class="category-link" href="../../../categories/database/hadoop/">hadoop</a>, <a class="category-link" href="../../../categories/database/hadoop/Hive/">Hive</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h2 id="Hive-简介">Hive 简介</h2>
<p>Hive 是一个基于 hadoop 的开源数据仓库工具，用于存储和处理海量结构化数据。它把海量数据存储于 hadoop 文件系统，而不是数据库，但提供了一套类数据库的数据存储和处理机制，并采用 HQL （类 SQL ）语言对这些数据进行自动化管理和处理。我们可以把 Hive 中海量结构化数据看成一个个的表，而实际上这些数据是分布式存储在 HDFS 中的。 Hive 经过对语句进行解析和转换，最终生成一系列基于 hadoop 的 map/reduce 任务，通过执行这些任务完成数据处理。</p>
<p>Hive 诞生于 facebook 的日志分析需求，面对海量的结构化数据， Hive 以较低的成本完成了以往需要大规模数据库才能完成的任务，并且学习门槛相对较低，应用开发灵活而高效。</p>
<p>Hive 自 2009.4.29 发布第一个官方稳定版 0.3.0 至今，不过一年的时间，正在慢慢完善，网上能找到的相关资料相当少，尤其中文资料更少，本文结合业务对 Hive 的应用做了一些探索，并把这些经验做一个总结，所谓前车之鉴，希望读者能少走一些弯路。</p>
<h2 id="准备工作">准备工作</h2>
<h3 id="环境">环境</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">JDK:1.8  </span><br><span class="line">Hadoop Release:2.7.4  </span><br><span class="line">centos:7.3  </span><br><span class="line"></span><br><span class="line">node1（master）  主机: 192.168.252.121  </span><br><span class="line">node2（slave1）  从机: 192.168.252.122  </span><br><span class="line">node3（slave2）  从机: 192.168.252.123  </span><br><span class="line"></span><br><span class="line">node4（mysql）   从机: 192.168.252.124  </span><br></pre></td></tr></table></figure>
<h3 id="依赖环境">依赖环境</h3>
<p>安装**<code>Apache Hive</code>**前提是要先安装<code>hadoop</code>集群，并且hive只需要在hadoop的namenode节点集群里安装即可（需要在有的namenode上安装)，可以不在datanode节点的机器上安装。还需要说明的是，虽然修改配置文件并不需要把hadoop运行起来，但是本文中用到了hadoop的hdfs命令，在执行这些命令时你必须确保hadoop是正在运行着的，而且启动hive的前提也需要hadoop在正常运行着，所以建议先把hadoop集群启动起来。</p>
<p>安装**<code>MySQL</code>** 用于存储 Hive 的元数据（也可以用 Hive 自带的嵌入式数据库 Derby，但是 Hive 的生产环境一般不用 Derby），这里只需要安装 MySQL 单机版即可，如果想保证高可用的化，也可以部署 MySQL 主从模式；</p>
<p><strong>Hadoop</strong></p>
<p><a href="https://chankein.github.io/2017/06/16/database/Hadoop-2-7-4-%E9%9B%86%E7%BE%A4%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA/">Hadoop-2.7.4 集群快速搭建</a></p>
<p><strong>MySQL</strong> 随意任选其一</p>
<p><a href="https://chankein.github.io/2017/08/16/database/CentOs7-3-%E5%AE%89%E8%A3%85-MySQL-5-7-19-%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%89%88%E6%9C%AC/">CentOs7.3 安装 MySQL 5.7.19 二进制版本</a></p>
<p><a href="https://chankein.github.io/2017/09/16/database/%E6%90%AD%E5%BB%BAMySQL5-7-19%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E4%BB%A5%E5%8F%8A%E5%A4%8D%E5%88%B6%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82%E5%88%86%E6%9E%90/">搭建 MySQL 5.7.19 主从复制，以及复制实现细节分析</a></p>
<h2 id="安装">安装</h2>
<h3 id="下载解压">下载解压</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">su hadoop</span><br><span class="line">cd /home/hadoop/</span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/apache/hive/hive-2.3.0/apache-hive-2.3.0-bin.tar.gz</span><br><span class="line">tar -zxvf apache-hive-2.3.0-bin.tar.gz</span><br><span class="line">mv apache-hive-2.3.0-bin hive-2.3.0</span><br></pre></td></tr></table></figure>
<h3 id="环境变量">环境变量</h3>
<p>如果是对所有的用户都生效就修改<code>vi /etc/profile</code> 文件<br>
如果只针对当前用户生效就修改 <code>vi ~/.bahsrc</code> 文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/profile</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#hive</span><br><span class="line">export PATH=$&#123;HIVE_HOME&#125;/bin:$PATH</span><br><span class="line">export HIVE_HOME=/home/hadoop/hive-2.3.0/</span><br></pre></td></tr></table></figure>
<p>使环境变量生效，运行 <code>source /etc/profile</code>使<code>/etc/profile</code>文件生效</p>
<h3 id="Hive-配置-Hadoop-HDFS">Hive 配置 Hadoop HDFS</h3>
<h4 id="复制-hive-site-xml">复制 hive-site.xml</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop/hive-2.3.0/conf</span><br><span class="line">cp hive-default.xml.template hive-site.xml</span><br></pre></td></tr></table></figure>
<h4 id="新建-hdfs-目录">新建 hdfs 目录</h4>
<p>使用 hadoop 新建 hdfs 目录,因为在 hive-site.xml 中有默认如下配置：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/user/hive/warehouse&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;location of default database for the warehouse&lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br></pre></td></tr></table></figure>
<p>进入 hadoop 安装目录 执行hadoop命令新建/user/hive/warehouse目录，并授权，用于存储文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop/hadoop-2.7.4</span><br><span class="line"></span><br><span class="line">bin/hadoop fs -mkdir -p /user/hive/warehouse  </span><br><span class="line">bin/hadoop fs -mkdir -p /user/hive/tmp  </span><br><span class="line">bin/hadoop fs -mkdir -p /user/hive/log  </span><br><span class="line">bin/hadoop fs -chmod -R 777 /user/hive/warehouse  </span><br><span class="line">bin/hadoop fs -chmod -R 777 /user/hive/tmp  </span><br><span class="line">bin/hadoop fs -chmod -R 777 /user/hive/log  </span><br></pre></td></tr></table></figure>
<p>用以下命令检查目录是否创建成功</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop fs -ls /user/hive</span><br></pre></td></tr></table></figure>
<h4 id="修改-hive-site-xml">修改 hive-site.xml</h4>
<p>搜索hive.exec.scratchdir,将该name对应的value修改为/user/hive/tmp</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;  </span><br><span class="line">    &lt;name&gt;hive.exec.scratchdir&lt;/name&gt;  </span><br><span class="line">    &lt;value&gt;/user/hive/tmp&lt;/value&gt;  </span><br><span class="line">&lt;/property&gt;  </span><br></pre></td></tr></table></figure>
<p>搜索hive.querylog.location,将该name对应的value修改为/user/hive/log/hadoop</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.querylog.location&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/user/hive/log/hadoop&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Location of Hive run time structured log file&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<p>搜索javax.jdo.option.connectionURL,将该name对应的value修改为MySQL的地址</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;jdbc:mysql://192.168.252.124:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;</span><br><span class="line">      JDBC connect string for a JDBC metastore.</span><br><span class="line">      To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.</span><br><span class="line">      For example, jdbc:postgresql://myhost/db?ssl=true for postgres database.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br></pre></td></tr></table></figure>
<p>搜索javax.jdo.option.ConnectionDriverName，将该name对应的value修改为MySQL驱动类路径</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<p>搜索javax.jdo.option.ConnectionUserName，将对应的value修改为MySQL数据库登录名</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Username to use against metastore database&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<p>搜索javax.jdo.option.ConnectionPassword，将对应的value修改为MySQL数据库的登录密码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;mima&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;password to use against metastore database&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<h4 id="创建-tmp-文件">创建 tmp 文件</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /home/hadoop/hive-2.3.0/tmp</span><br></pre></td></tr></table></figure>
<p>并在 <code>hive-site.xml</code> 中修改</p>
<p>把<code>&#123;system:java.io.tmpdir&#125;</code> 改成 /home/hadoop/hive-2.3.0/tmp</p>
<p>把 <code>&#123;system:user.name&#125;</code> 改成 <code>&#123;user.name&#125;</code></p>
<h4 id="新建-hive-env-sh">新建 <a target="_blank" rel="noopener" href="http://hive-env.sh">hive-env.sh</a></h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cp hive-env.sh.template hive-env.sh</span><br><span class="line"></span><br><span class="line">vi hive-env.sh</span><br><span class="line"></span><br><span class="line">HADOOP_HOME=/home/hadoop/hadoop-2.7.4/</span><br><span class="line">export HIVE_CONF_DIR=/home/hadoop/hive-2.3.0/conf</span><br><span class="line">export HIVE_AUX_JARS_PATH=/home/hadoop/hive-2.3.0/lib</span><br></pre></td></tr></table></figure>
<h4 id="下载-mysql-驱动包">下载 mysql 驱动包</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop/hive-2.3.0/lib</span><br><span class="line"></span><br><span class="line">wget http://central.maven.org/maven2/mysql/mysql-connector-java/5.1.38/mysql-connector-java-5.1.38.jar</span><br></pre></td></tr></table></figure>
<h3 id="初始化-mysql">初始化 mysql</h3>
<h4 id="MySQL数据库进行初始化">MySQL数据库进行初始化</h4>
<p>首先确保 mysql 中已经创建 <code>hive</code> 库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop/hive-2.3.0/bin</span><br><span class="line">./schematool -initSchema -dbType mysql</span><br></pre></td></tr></table></figure>
<p>如果看到如下,表示初始化成功</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Starting metastore schema initialization to 2.3.0</span><br><span class="line">Initialization script hive-schema-2.3.0.mysql.sql</span><br><span class="line">Initialization script completed</span><br><span class="line">schemaTool completed</span><br></pre></td></tr></table></figure>
<h4 id="查看-mysql-数据库">查看 mysql 数据库</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/mysql/bin/mysql -uroot -p</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show databases;</span><br><span class="line">+--------------------+</span><br><span class="line">| Database           |</span><br><span class="line">+--------------------+</span><br><span class="line">| information_schema |</span><br><span class="line">| hive               |</span><br><span class="line">| mysql              |</span><br><span class="line">| performance_schema |</span><br><span class="line">| sys                |</span><br><span class="line">+--------------------+</span><br><span class="line">5 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; use hive;</span><br><span class="line">Reading table information for completion of table and column names</span><br><span class="line">You can turn off this feature to get a quicker startup with -A</span><br><span class="line"></span><br><span class="line">Database changed</span><br><span class="line">mysql&gt; show tables;</span><br><span class="line">+---------------------------+</span><br><span class="line">| Tables_in_hive            |</span><br><span class="line">+---------------------------+</span><br><span class="line">| AUX_TABLE                 |</span><br><span class="line">| BUCKETING_COLS            |</span><br><span class="line">| CDS                       |</span><br><span class="line">| COLUMNS_V2                |</span><br><span class="line">| COMPACTION_QUEUE          |</span><br><span class="line">| COMPLETED_COMPACTIONS     |</span><br><span class="line">| COMPLETED_TXN_COMPONENTS  |</span><br><span class="line">| DATABASE_PARAMS           |</span><br><span class="line">| DBS                       |</span><br><span class="line">| DB_PRIVS                  |</span><br><span class="line">| DELEGATION_TOKENS         |</span><br><span class="line">| FUNCS                     |</span><br><span class="line">| FUNC_RU                   |</span><br><span class="line">| GLOBAL_PRIVS              |</span><br><span class="line">| HIVE_LOCKS                |</span><br><span class="line">| IDXS                      |</span><br><span class="line">| INDEX_PARAMS              |</span><br><span class="line">| KEY_CONSTRAINTS           |</span><br><span class="line">| MASTER_KEYS               |</span><br><span class="line">| NEXT_COMPACTION_QUEUE_ID  |</span><br><span class="line">| NEXT_LOCK_ID              |</span><br><span class="line">| NEXT_TXN_ID               |</span><br><span class="line">| NOTIFICATION_LOG          |</span><br><span class="line">| NOTIFICATION_SEQUENCE     |</span><br><span class="line">| NUCLEUS_TABLES            |</span><br><span class="line">| PARTITIONS                |</span><br><span class="line">| PARTITION_EVENTS          |</span><br><span class="line">| PARTITION_KEYS            |</span><br><span class="line">| PARTITION_KEY_VALS        |</span><br><span class="line">| PARTITION_PARAMS          |</span><br><span class="line">| PART_COL_PRIVS            |</span><br><span class="line">| PART_COL_STATS            |</span><br><span class="line">| PART_PRIVS                |</span><br><span class="line">| ROLES                     |</span><br><span class="line">| ROLE_MAP                  |</span><br><span class="line">| SDS                       |</span><br><span class="line">| SD_PARAMS                 |</span><br><span class="line">| SEQUENCE_TABLE            |</span><br><span class="line">| SERDES                    |</span><br><span class="line">| SERDE_PARAMS              |</span><br><span class="line">| SKEWED_COL_NAMES          |</span><br><span class="line">| SKEWED_COL_VALUE_LOC_MAP  |</span><br><span class="line">| SKEWED_STRING_LIST        |</span><br><span class="line">| SKEWED_STRING_LIST_VALUES |</span><br><span class="line">| SKEWED_VALUES             |</span><br><span class="line">| SORT_COLS                 |</span><br><span class="line">| TABLE_PARAMS              |</span><br><span class="line">| TAB_COL_STATS             |</span><br><span class="line">| TBLS                      |</span><br><span class="line">| TBL_COL_PRIVS             |</span><br><span class="line">| TBL_PRIVS                 |</span><br><span class="line">| TXNS                      |</span><br><span class="line">| TXN_COMPONENTS            |</span><br><span class="line">| TYPES                     |</span><br><span class="line">| TYPE_FIELDS               |</span><br><span class="line">| VERSION                   |</span><br><span class="line">| WRITE_SET                 |</span><br><span class="line">+---------------------------+</span><br><span class="line">57 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>
<h3 id="启动-Hive">启动 Hive</h3>
<h4 id="简单测试">简单测试</h4>
<p><strong>启动Hive</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop/hive-2.3.0/bin</span><br><span class="line"></span><br><span class="line">./hive</span><br></pre></td></tr></table></figure>
<p><strong>创建 hive 库</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive&gt;  create database ymq;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.742 seconds</span><br></pre></td></tr></table></figure>
<p><strong>选择库</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; use ymq;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.036 seconds</span><br></pre></td></tr></table></figure>
<p><strong>创建表</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; create table test (mykey string,myval string);</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.569 seconds</span><br></pre></td></tr></table></figure>
<p><strong>插入数据</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; insert into test values(&quot;1&quot;,&quot;www.ymq.io&quot;);</span><br><span class="line"></span><br><span class="line">WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span><br><span class="line">Query ID = hadoop_20170922011126_abadfa44-8ebe-4ffc-9615-4241707b3c03</span><br><span class="line">Total jobs = 3</span><br><span class="line">Launching Job 1 out of 3</span><br><span class="line">Number of reduce tasks is set to 0 since there&#x27;s no reduce operator</span><br><span class="line">Starting Job = job_1506006892375_0001, Tracking URL = http://node1:8088/proxy/application_1506006892375_0001/</span><br><span class="line">Kill Command = /home/hadoop/hadoop-2.7.4//bin/hadoop job  -kill job_1506006892375_0001</span><br><span class="line">Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0</span><br><span class="line">2017-09-22 01:12:12,763 Stage-1 map = 0%,  reduce = 0%</span><br><span class="line">2017-09-22 01:12:20,751 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.24 sec</span><br><span class="line">MapReduce Total cumulative CPU time: 1 seconds 240 msec</span><br><span class="line">Ended Job = job_1506006892375_0001</span><br><span class="line">Stage-4 is selected by condition resolver.</span><br><span class="line">Stage-3 is filtered out by condition resolver.</span><br><span class="line">Stage-5 is filtered out by condition resolver.</span><br><span class="line">Moving data to directory hdfs://node1:9000/user/hive/warehouse/ymq.db/test/.hive-staging_hive_2017-09-22_01-11-26_242_8022847052615616955-1/-ext-10000</span><br><span class="line">Loading data to table ymq.test</span><br><span class="line">MapReduce Jobs Launched: </span><br><span class="line">Stage-Stage-1: Map: 1   Cumulative CPU: 1.24 sec   HDFS Read: 4056 HDFS Write: 77 SUCCESS</span><br><span class="line">Total MapReduce CPU Time Spent: 1 seconds 240 msec</span><br><span class="line">OK</span><br><span class="line">Time taken: 56.642 seconds</span><br></pre></td></tr></table></figure>
<p>查询数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select * from test;</span><br><span class="line">OK</span><br><span class="line">1    www.ymq.io</span><br><span class="line">Time taken: 0.253 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure>
<h4 id="页面数据">页面数据</h4>
<p><strong>在界面上查看刚刚写入的hdfs数据</strong></p>
<p><img src="/assets/images/hive1.webp" alt="图片描述" title="图片描述"></p>
<p><img src="/assets/images/hive2.webp" alt="图片描述" title="图片描述"></p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="../../../2017/11/25/database/Hive-2-3-0-%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                留言與分享
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="../../../2017/11/16/database/CentOs7-3-Hadoop-ssh-%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/"
                            aria-label=": CentOs7.3 hadoop ssh 免密登录"
                        >
                            CentOs7.3 hadoop ssh 免密登录
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2017-11-16T18:42:22+08:00">
	
		    2017 年 11 月 16 日
    	
    </time>
    
        <span>分類 </span>
        
    <a class="category-link" href="../../../categories/database/">database</a>, <a class="category-link" href="../../../categories/database/hadoop/">hadoop</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h3 id="环境">环境</h3>
<p>三台虚拟机(IP)：</p>
<ul>
<li>192.168.252.121</li>
<li>192.168.252.122</li>
<li>192.168.252.123</li>
</ul>
<h3 id="1-修改主机名">1.修改主机名</h3>
<p>修改三台主机名，以此类推，node1，node3，node3</p>
<p>命令格式</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl set-hostname &lt;hostname&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo hostnamectl set-hostname node1</span><br></pre></td></tr></table></figure>
<p>剩下的虚拟机依次修改<code>hostnamectl set-hostname[1-3]</code></p>
<p><strong>重启操作系统</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ reboot</span><br></pre></td></tr></table></figure>
<h3 id="2-修改映射关系">2.修改映射关系</h3>
<p>1.在 node1 的 <code>/etc/hosts</code> 文件下添加如下内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">su hadoop</span><br><span class="line">vi /etc/hosts</span><br></pre></td></tr></table></figure>
<p>2.查看修改后的<code>/etc/hosts</code> 文件内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/hosts</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"># 以下是添加的</span><br><span class="line">192.168.252.121 node1</span><br><span class="line">192.168.252.122 node2</span><br><span class="line">192.168.252.123 node3</span><br></pre></td></tr></table></figure>
<p>2.将集群node1 上的文件<code>hosts</code>文件 通过 <code>scp</code> 命令复制发送到集群的每一个节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for a in &#123;1..3&#125; ; do sudo scp /etc/hosts hadoop@node$a:/etc/hosts ; done</span><br></pre></td></tr></table></figure>
<p>3.检查是否集群每一个节点的 <code>hosts</code> 文件都已经修改过来了</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for a in &#123;1..3&#125; ; do sudo ssh hadoop@node$a cat /etc/hosts ; done</span><br></pre></td></tr></table></figure>
<h3 id="3-启动-ssh-无密登录">3.启动 ssh 无密登录</h3>
<p>1.在集群node1的 <code>/etc/ssh/sshd_config</code> 文件去掉以下选项的注释</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/ssh/sshd_config </span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RSAAuthentication yes      #开启私钥验证</span><br><span class="line">PubkeyAuthentication yes   #开启公钥验证</span><br></pre></td></tr></table></figure>
<p>2.将集群node1 修改后的 <code>/etc/ssh/sshd_config</code> 通过 <code>scp</code> 命令复制发送到集群的每一个节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for a in &#123;1..3&#125; ; do  sudo scp /etc/ssh/sshd_config hadoop@node$a:/etc/ssh/sshd_config ; done</span><br></pre></td></tr></table></figure>
<h3 id="4-生成公钥、私钥">4.生成公钥、私钥</h3>
<p>1.在集群的每一个节点节点输入命令 <code>ssh-keygen -t rsa -P ''</code>，生成 key，一律回车</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -P &#x27;&#x27;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/home/hadoop/.ssh/id_rsa): </span><br><span class="line">Created directory &#x27;/home/hadoop/.ssh&#x27;.</span><br><span class="line">Your identification has been saved in /home/hadoop/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved in /home/hadoop/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">aa:be:0e:46:9a:e8:d5:dc:79:ea:5a:b8:9b:08:e2:dd hadoop@node2</span><br><span class="line">The key&#x27;s randomart image is:</span><br><span class="line">+--[ RSA 2048]----+</span><br><span class="line">|                 |</span><br><span class="line">|                 |</span><br><span class="line">|                 |</span><br><span class="line">|                 |</span><br><span class="line">|  .     S        |</span><br><span class="line">|.+  o o..        |</span><br><span class="line">|=.o. +.+ .       |</span><br><span class="line">|+.+.o.+ o        |</span><br><span class="line">| o ==E+o         |</span><br><span class="line">+-----------------+</span><br></pre></td></tr></table></figure>
<p>2.在集群的node1 节点输入命令</p>
<p>将集群每一个节点的公钥<code>id_rsa.pub</code>放入到自己的认证文件中<code>authorized_keys</code>;</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for a in &#123;1..3&#125;; do sudo ssh hadoop@node$a cat /home/hadoop/.ssh/id_rsa.pub &gt;&gt; /home/hadoop/.ssh/authorized_keys; done</span><br></pre></td></tr></table></figure>
<p>3.在集群的node1 节点输入命令</p>
<p>将自己的认证文件 <code>authorized_keys</code> <code>通过</code> scp <code>命令复制发送到每一个节点上去:</code> /home/hadoop/.ssh/authorized_keys`</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for a in &#123;1..3&#125;; do sudo scp /home/hadoop/.ssh/authorized_keys hadoop@node$a:/home/hadoop/.ssh/authorized_keys ; done</span><br></pre></td></tr></table></figure>
<p>4.非ROOT 用户需赋权限</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chmod 700 /home/hadoop/.ssh/</span><br><span class="line">chmod 700 /home/hadoop/</span><br><span class="line">chmod 600 /home/hadoop/.ssh/authorized_keys </span><br></pre></td></tr></table></figure>
<p>5.在集群的每一个节点节点输入命令</p>
<p>接重启ssh服务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl restart sshd.service</span><br></pre></td></tr></table></figure>
<h3 id="6-验证-ssh-无密登录">6.验证 ssh 无密登录</h3>
<p>开一个其他窗口测试下能否免密登陆</p>
<p>例如：在node3</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh hadoop@node2</span><br></pre></td></tr></table></figure>
<p><code>exit</code> 退出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node1 ~]# exit</span><br><span class="line">logout</span><br><span class="line">Connection to node1 closed.</span><br></pre></td></tr></table></figure>
<p>注意：开新的其他窗口测试下能否免密登陆，把当前窗口都关了</p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="../../../2017/11/16/database/CentOs7-3-Hadoop-ssh-%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                留言與分享
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="../../../2017/11/16/database/HBase-%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA/"
                            aria-label=": HBase 深入浅出"
                        >
                            HBase 深入浅出
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2017-11-16T13:09:41+08:00">
	
		    2017 年 11 月 16 日
    	
    </time>
    
        <span>分類 </span>
        
    <a class="category-link" href="../../../categories/database/">database</a>, <a class="category-link" href="../../../categories/database/hadoop/">hadoop</a>, <a class="category-link" href="../../../categories/database/hadoop/HBase/">HBase</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h2 id="HBase-深入浅出">HBase 深入浅出</h2>
<h3 id="HBase-在大数据生态圈中的位置">HBase 在大数据生态圈中的位置</h3>
<p>提到大数据的存储，大多数人首先联想到的是 Hadoop 和 Hadoop 中的 HDFS 模块。大家熟知的 Spark、以及 Hadoop 的 MapReduce，可以理解为一种计算框架。而 HDFS，我们可以认为是为计算框架服务的存储层。因此不管是 Spark 还是 MapReduce，都需要使用 HDFS 作为默认的持久化存储层。那么 HBase 又是什么，可以用在哪里，解决什么样的问题？简单地，我们可以认为 HBase 是一种类似于数据库的存储层，也就是说 HBase 适用于结构化的存储。并且 HBase 是一种列式的分布式数据库，是由当年的 Google 公布的 BigTable 的论文而生。不过这里也要注意 HBase 底层依旧依赖 HDFS 来作为其物理存储，这点类似于 Hive。</p>
<p>可能有的读者会好奇 HBase 于 Hive 的区别，我们简单的梳理一下 Hive 和 HBase 的应用场景：</p>
<p>Hive 适合用来对一段时间内的数据进行分析查询，例如，用来计算趋势或者网站的日志。Hive 不应该用来进行实时的查询（Hive 的设计目的，也不是支持实时的查询）。因为它需要很长时间才可以返回结果；HBase 则非常适合用来进行大数据的实时查询，例如 Facebook 用 HBase 进行消息和实时的分析。对于 Hive 和 HBase 的部署来说，也有一些区别，Hive 一般只要有 Hadoop 便可以工作。而 HBase 则还需要 Zookeeper 的帮助（Zookeeper，是一个用来进行分布式协调的服务，这些服务包括配置服务，维护元信息和命名空间服务）。再而，HBase 本身只提供了 Java 的 API 接口，并不直接支持 SQL 的语句查询，而 Hive 则可以直接使用 HQL（一种类 SQL 语言）。如果想要在 HBase 上使用 SQL，则需要联合使用 Apache Phonenix，或者联合使用 Hive 和 HBase。但是和上面提到的一样，如果集成使用 Hive 查询 HBase 的数据，则无法绕过 MapReduce，那么实时性还是有一定的损失。Phoenix 加 HBase 的组合则不经过 MapReduce 的框架，因此当使用 Phoneix 加 HBase 的组成，实时性上会优于 Hive 加 HBase 的组合，我们后续也会示例性介绍如何使用两者。最后我们再提下 Hive 和 HBase 所使用的存储层，默认情况下 Hive 和 HBase 的存储层都是 HDFS。但是 HBase 在一些特殊的情况下也可以直接使用本机的文件系统。例如 Ambari 中的 AMS 服务直接在本地文件系统上运行 HBase。</p>
<h3 id="HBase-与传统关系数据库的区别">HBase 与传统关系数据库的区别</h3>
<p>首先让我们了解下什么是 ACID。ACID 是指数据库事务正确执行的四个基本要素的缩写，其包含：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）以及持久性（Durability）。对于一个支持事务（Transaction）的数据库系统，必需要具有这四种特性，否则在事务过程（Transaction Processing）当中无法保证数据的正确性，交易过程极可能达不到交易方的要求。下面，我们就简单的介绍下这 4 个特性的含义。</p>
<ul>
<li>原子性(Atomicity)是指一个事务要么全部执行,要么全部不执行。换句话说，一个事务不可能只执行了一半就停止了。比如一个事情分为两步完成才可以完成，那么这两步必须同时完成，要么一步也不执行，绝不会停留在某一个中间状态。如果事物执行过程中，发生错误，系统会将事物的状态回滚到最开始的状态。</li>
<li>一致性(Consistency)是指事务的运行并不改变数据库中数据的一致性。也就是说，无论并发事务有多少个，但是必须保证数据从一个一致性的状态转换到另一个一致性的状态。例如有 a、b 两个账户，分别都是 10。当 a 增加 5 时，b 也会随着改变，总值 20 是不会改变的。</li>
<li>隔离性（Isolation）是指两个以上的事务不会出现交错执行的状态。因为这样可能会导致数据不一致。如果有多个事务，运行在相同的时间内，执行相同的功能，事务的隔离性将确保每一事务在系统中认为只有该事务在使用系统。这种属性有时称为串行化，为了防止事务操作间的混淆，必须串行化或序列化请求，使得在同一时间仅有一个请求用于同一数据。</li>
<li>持久性(Durability)指事务执行成功以后,该事务对数据库所作的更改便是持久的保存在数据库之中，不会无缘无故的回滚。</li>
</ul>
<p>在具体的介绍 HBase 之前，我们先简单对比下 HBase 与传统关系数据库的（RDBMS，全称为 Relational Database Management System）区别。如表 1 所示。</p>
<p>表 1. HBase 与 RDBMS 的区别</p>
<table>
<thead>
<tr>
<th></th>
<th>HBase</th>
<th>RDBMS</th>
</tr>
</thead>
<tbody>
<tr>
<td>硬件架构</td>
<td>类似于 Hadoop 的分布式集群，硬件成本低廉</td>
<td>传统的多核系统，硬件成本昂贵</td>
</tr>
<tr>
<td>容错性</td>
<td>由软件架构实现，由于由多个节点组成，所以不担心一点或几点宕机</td>
<td>一般需要额外硬件设备实现 HA 机制</td>
</tr>
<tr>
<td>数据库大小</td>
<td>PB</td>
<td>GB、TB</td>
</tr>
<tr>
<td>数据排布方式</td>
<td>稀疏的、分布的多维的 Map</td>
<td>以行和列组织</td>
</tr>
<tr>
<td>数据类型</td>
<td>Bytes</td>
<td>丰富的数据类型</td>
</tr>
<tr>
<td>事物支持</td>
<td>ACID 只支持单个 Row 级别</td>
<td>全面的 ACID 支持，对 Row 和表</td>
</tr>
<tr>
<td>查询语言</td>
<td>只支持 Java API （除非与其他框架一起使用，如 Phoenix、Hive）</td>
<td>SQL</td>
</tr>
<tr>
<td>索引</td>
<td>只支持 Row-key，除非与其他技术一起应用，如 Phoenix、Hive</td>
<td>支持</td>
</tr>
<tr>
<td>吞吐量</td>
<td>百万查询/每秒</td>
<td>数千查询/每秒</td>
</tr>
</tbody>
</table>
<p>理解了上面的表格之后，我们在看看数据是如何在 HBase 以及 RDBMS 中排布的。首先，数据在 RDBMS 的排布大致如表 2。</p>
<p>表 2. 数据在 RDBMS 中的排布示例</p>
<table>
<thead>
<tr>
<th>ID</th>
<th>姓</th>
<th>名</th>
<th>密码</th>
<th>时间戳</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>张</td>
<td>三</td>
<td>111</td>
<td>20160719</td>
</tr>
<tr>
<td>2</td>
<td>李</td>
<td>四</td>
<td>222</td>
<td>20160720</td>
</tr>
</tbody>
</table>
<p>那么数据在 HBase 中的排布会是什么样子呢？如表 3 所示（这只是逻辑上的排布）。</p>
<p>表 3. 数据在 HBase 中的排布（逻辑上）</p>
<table>
<thead>
<tr>
<th>Row-Key</th>
<th>Value（CF、Qualifier、Version）</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>info{‘姓’: ‘张’，‘名’:‘三’}</td>
</tr>
<tr>
<td>pwd{‘密码’: ‘111’}</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>Info{‘姓’: ‘李’，‘名’:‘四’}</td>
</tr>
<tr>
<td>pwd{‘密码’: ‘222’}</td>
<td></td>
</tr>
</tbody>
</table>
<p>从上面示例表中，我们可以看出，在 HBase 中首先会有 Column Family 的概念，简称为 CF。CF 一般用于将相关的列（Column）组合起来。在物理上 HBase 其实是按 CF 存储的，只是按照 Row-key 将相关 CF 中的列关联起来。物理上的数据排布大致可以如表 4 所示。</p>
<p>表 4. 数据在 HBase 中的排布</p>
<table>
<thead>
<tr>
<th>Row-Key</th>
<th>CF:Column-Key</th>
<th>时间戳</th>
<th>Cell Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>info:fn</td>
<td>123456789</td>
<td>三</td>
</tr>
<tr>
<td>1</td>
<td>info:ln</td>
<td>123456789</td>
<td>张</td>
</tr>
<tr>
<td>2</td>
<td>info:fn</td>
<td>123456789</td>
<td>四</td>
</tr>
<tr>
<td>2</td>
<td>info:ln</td>
<td>123456789</td>
<td>李</td>
</tr>
</tbody>
</table>
<p>我们已经提到 HBase 是按照 CF 来存储数据的。在表 3 中，我们看到了两个 CF，分别是 info 和 pwd。info 存储着姓名相关列的数据，而 pwd 则是密码相关的数据。上表便是 info 这个 CF 存储在 Hbase 中的数据排布。Pwd 的数据排布是类似的。上表中的 fn 和 ln 称之为 Column-key 或者 Qulifimer。在 Hbase 中，Row-key 加上 CF 加上 Qulifier 再加上一个时间戳才可以定位到一个单元格数据（Hbase 中每个单元格默认有 3 个时间戳的版本数据）。初学者，在一开始接触这些概念是很容易混淆。其实不管是 CF 还是 Qulifier 都是客户定义出来的。也就是说在 HBase 中创建表格时，就需要指定表格的 CF、Row-key 以及 Qulifier。我们会在后续的介绍中，尝试指定这些相关的概念，以便加深理解。这里我们先通过下图理解下 HBase 中，逻辑上的数据排布与物理上的数据排布之间的关系。</p>
<p><strong>图 1. Hbase 中逻辑上数据的排布与物理上排布的关联</strong></p>
<p><img src="/assets/images/hbase1.webp" alt="图片描述" title="图片描述"></p>
<p>从上图我们看到 Row1 到 Row5 的数据分布在两个 CF 中，并且每个 CF 对应一个 HFile。并且逻辑上每一行中的一个单元格数据，对应于 HFile 中的一行，然后当用户按照 Row-key 查询数据的时候，HBase 会遍历两个 HFile，通过相同的 Row-Key 标识，将相关的单元格组织成行返回，这样便有了逻辑上的行数据。讲解到这，我们就大致了解 HBase 中的数据排布格式，以及与 RDBMS 的一些区别。</p>
<p>对于 RDBMS 来说，一般都是以 SQL 作为为主要的访问方式。而 HBase 是一种&quot;NoSQL&quot;数据库。&quot;NoSQL&quot;是一个通用词表示该数据库并</p>
<p>是 RDBMS 。现在的市面上有许多种 NoSQL 数据库，如 BerkeleyDB 是本地 NoSQL 数据库的例子, HBase 则为大型分布式 NoSql 数据库。从技术上来说，Hbase 更像是&quot;数据存储&quot;而非&quot;数据库&quot;（HBase 和 HDFS 都属于大数据的存储层）。因此，HBase 缺少很多 RDBMS 特性，如列类型，二级索引，触发器和高级查询语言等。然而, HBase 也具有许多其他特征同时支持线性化和模块化扩充。最明显的方式，我们可以通过增加 Region Server 的数量扩展 HBase。并且 HBase 可以放在普通的服务器中，例如将集群从 5 个扩充到 10 个 Region Server 时，存储空间和处理容量都可以同时翻倍。当然 RDBMS 也能很好的扩充，但仅对一个点，尤其是对一个单独数据库服务器而言，为了更好的性能，往往需要特殊的硬件和存储设备（往往价格也非常昂贵）。</p>
<h3 id="HBase-相关模块以及-HBase-表格特性">HBase 相关模块以及 HBase 表格特性</h3>
<p>在这里，让我们了解下 HBase 都有哪些模块，以及大致的工作流程。前面我们提到过 HBase 也是构建于 HDFS 之上，这是正确的，但也不是完全正确。HBase 其实也支持直接在本地文件系统之上运行，不过这样的 HBase 只能运行在一台机器上，那么对于分布式大数据的环境是没有意义的（这也是所谓的 HBase 的单机模式）。一般只用于测试或者验证某一个 HBase 的功能，后面我们在详细的介绍 HBase 的几种运行模式。这里我们只要记得在分布式的生产环境中，HBase 需要运行在 HDFS 之上，以 HDFS 作为其基础的存储设施。HBase 上层提供了访问的数据的 Java API 层，供应用访问存储在 HBase 的数据。在 HBase 的集群中主要由 Master 和 Region Server 组成，以及 Zookeeper，具体模块如下图所示。</p>
<p><strong>图 2. HBase 的相关模块</strong></p>
<p><img src="/assets/images/hbase2.webp" alt="图片描述" title="图片描述"></p>
<p>接下来，我们简单的一一介绍下 HBase 中相关模块的作用。</p>
<ul>
<li>
<p><strong>Master</strong></p>
<p>HBase Master 用于协调多个 Region Server，侦测各个 Region Server 之间的状态，并平衡 Region Server 之间的负载。HBase Master 还有一个职责就是负责分配 Region 给 Region Server。HBase 允许多个 Master 节点共存，但是这需要 Zookeeper 的帮助。不过当多个 Master 节点共存时，只有一个 Master 是提供服务的，其他的 Master 节点处于待命的状态。当正在工作的 Master 节点宕机时，其他的 Master 则会接管 HBase 的集群。</p>
</li>
<li>
<p><strong>Region Server</strong></p>
<p>对于一个 Region Server 而言，其包括了多个 Region。Region Server 的作用只是管理表格，以及实现读写操作。Client 直接连接 Region Server，并通信获取 HBase 中的数据。对于 Region 而言，则是真实存放 HBase 数据的地方，也就说 Region 是 HBase 可用性和分布式的基本单位。如果当一个表格很大，并由多个 CF 组成时，那么表的数据将存放在多个 Region 之间，并且在每个 Region 中会关联多个存储的单元（Store）。</p>
</li>
<li>
<p><strong>Zookeeper</strong></p>
<p>对于 HBase 而言，Zookeeper 的作用是至关重要的。首先 Zookeeper 是作为 HBase Master 的 HA 解决方案。也就是说，是 Zookeeper 保证了至少有一个 HBase Master 处于运行状态。并且 Zookeeper 负责 Region 和 Region Server 的注册。其实 Zookeeper 发展到目前为止，已经成为了分布式大数据框架中容错性的标准框架。不光是 HBase，几乎所有的分布式大数据相关的开源框架，都依赖于 Zookeeper 实现 HA。</p>
</li>
</ul>
<p>一个完整分布式的 HBase 的工作原理示意图如下：</p>
<p><strong>图 3. HBase 的工作原理</strong></p>
<p><img src="/assets/images/hbase3.webp" alt="图片描述" title="图片描述"></p>
<p>在上面的图中，我们需要注意几个我们之前没有提到的概念：Store、MemStore、StoreFile 以及 HFile。带着这几个新的概念，我们完整的梳理下整个 HBase 的工作流程。</p>
<p>首先我们需要知道 HBase 的集群是通过 Zookeeper 来进行机器之前的协调，也就是说 HBase Master 与 Region Server 之间的关系是依赖 Zookeeper 来维护。当一个 Client 需要访问 HBase 集群时，Client 需要先和 Zookeeper 来通信，然后才会找到对应的 Region Server。每一个 Region Server 管理着很多个 Region。对于 HBase 来说，Region 是 HBase 并行化的基本单元。因此，数据也都存储在 Region 中。这里我们需要特别注意，每一个 Region 都只存储一个 Column Family 的数据，并且是该 CF 中的一段（按 Row 的区间分成多个 Region）。Region 所能存储的数据大小是有上限的，当达到该上限时（Threshold），Region 会进行分裂，数据也会分裂到多个 Region 中，这样便可以提高数据的并行化，以及提高数据的容量。每个 Region 包含着多个 Store 对象。每个 Store 包含一个 MemStore，和一个或多个 HFile。MemStore 便是数据在内存中的实体，并且一般都是有序的。当数据向 Region 写入的时候，会先写入 MemStore。当 MemStore 中的数据需要向底层文件系统倾倒（Dump）时（例如 MemStore 中的数据体积到达 MemStore 配置的最大值），Store 便会创建 StoreFile，而 StoreFile 就是对 HFile 一层封装。所以 MemStore 中的数据会最终写入到 HFile 中，也就是磁盘 IO。由于 HBase 底层依靠 HDFS，因此 HFile 都存储在 HDFS 之中。这便是整个 HBase 工作的原理简述。</p>
<p>我们了解了 HBase 大致的工作原理，那么在 HBase 的工作过程中，如何保证数据的可靠性呢？带着这个问题，我们理解下 HLog 的作用。HBase 中的 HLog 机制是 WAL 的一种实现，而 WAL（一般翻译为预写日志）是事务机制中常见的一致性的实现方式。每个 Region Server 中都会有一个 HLog 的实例，Region Server 会将更新操作（如 Put，Delete）先记录到 WAL（也就是 HLog）中，然后将其写入到 Store 的 MemStore，最终 MemStore 会将数据写入到持久化的 HFile 中（MemStore 到达配置的内存阀值）。这样就保证了 HBase 的写的可靠性。如果没有 WAL，当 Region Server 宕掉的时候，MemStore 还没有写入到 HFile，或者 StoreFile 还没有保存，数据就会丢失。或许有的读者会担心 HFile 本身会不会丢失，这是由 HDFS 来保证的。在 HDFS 中的数据默认会有 3 份。因此这里并不考虑 HFile 本身的可靠性。</p>
<p>前面，我们很多次提到了 HFile，也就是 HBase 持久化的存储文件。也许有的读者还不能完全理解 HFile，这里我们便详细的看看 HFile 的结构，如下图。</p>
<p><strong>图 4. HFile 的结构</strong></p>
<p><img src="/assets/images/hbase4.webp" alt="图片描述" title="图片描述"></p>
<p>从图中我们可以看到 HFile 由很多个数据块（Block）组成，并且有一个固定的结尾块。其中的数据块是由一个 Header 和多个 Key-Value 的键值对组成。在结尾的数据块中包含了数据相关的索引信息，系统也是通过结尾的索引信息找到 HFile 中的数据。HFile 中的数据块大小默认为 64KB。如果访问 HBase 数据库的场景多为有序的访问，那么建议将该值设置的大一些。如果场景多为随机访问，那么建议将该值设置的小一些。一般情况下，通过调整该值可以提高 HBase 的性能。</p>
<p>如果要用很短的一句话总结 HBase，我们可以认为 HBase 就是一个有序的多维 Map，其中每一个 Row-key 映射了许多数据，这些数据存储在 CF 中的 Column。我们可以用下图来表示这句话。</p>
<p><strong>图 5. HBase 的数据映射关系</strong></p>
<p><img src="/assets/images/hbase5.webp" alt="图片描述" title="图片描述"></p>
<h3 id="HBase-的使用建议">HBase 的使用建议</h3>
<p>之前我介绍了很多 HBase 与 RDBMS 的区别，以及一些优势的地方。那么什么时候最需要 HBase，或者说 HBase 是否可以替代原有的 RDBMS？对于这个问题，我们必须时刻谨记——HBase 并不适合所有问题，其设计目标并不是替代 RDBMS，而是对 RDBMS 的一个重要补充，尤其是对大数据的场景。当需要考量 HBase 作为一个备选项时，我们需要进行如下的调研工作。</p>
<p>首先，要确信有足够多数据，如果有上亿或上千亿行数据，HBase 才会是一个很好的备选。其次，需要确信业务上可以不依赖 RDBMS 的额外特性，例如，列数据类型, 二级索引，SQL 查询语言等。再而，需要确保有足够硬件。且不说 HBase，一般情况下当 HDFS 的集群小于 5 个数据节点时，也干不好什么事情 (HDFS 默认会将每一个 Block 数据备份 3 分)，还要加上一个 NameNode。</p>
<p>以下我给了一些使用 HBase 时候对表格设计的一些建议，读者也可以理解背后的含义。不过我并不希望这些建议成为使用 HBase 的教条，毕竟也有不尽合理的地方。首先，一个 HBase 数据库是否高效，很大程度会和 Row-Key 的设计有关。因此，如何设计 Row-key 是使用 HBase 时，一个非常重要的话题。随着数据访问方式的不同，Row-Key 的设计也会有所不同。不过概括起来的宗旨只有一个，那就是尽可能选择一个 Row-Key，可以使你的数据均匀的分布在集群中。这也很容易理解，因为 HBase 是一个分布式环境，Client 会访问不同 Region Server 获取数据。如果数据排布均匀在不同的多个节点，那么在批量的 Client 便可以从不同的 Region Server 上获取数据，而不是瓶颈在某一个节点，性能自然会有所提升。对于具体的建议我们一般有几条：</p>
<ol>
<li>当客户端需要频繁的写一张表，随机的 RowKey 会获得更好的性能。</li>
<li>当客户端需要频繁的读一张表，有序的 RowKey 则会获得更好的性能。</li>
<li>对于时间连续的数据（例如 log），有序的 RowKey 会很方便查询一段时间的数据（Scan 操作）。</li>
</ol>
<p>上面我们谈及了对 Row-Key 的设计，接着我们需要想想是否 Column Family 也会在不同的场景需要不同的设计方案呢。答案是肯定的，不过 CF 跟 Row-key 比较的话，确实也简单一些，但这并不意味着 CF 的设计就是一个琐碎的话题。在 RDBMS（传统关系数据库）系统中，我们知道如果当用户的信息分散在不同的表中，便需要根据一个 Key 进行 Join 操作。而在 HBase 中，我们需要设计 CF 来聚合用户所有相关信息。简单来说，就是需要将数据按类别（或者一个特性）聚合在一个或多个 CF 中。这样，便可以根据 CF 获取这类信息。上面，我们讲解过一个 Region 对应于一个 CF。那么设想，如果在一个表中定义了多个 CF 时，就必然会有多个 Region。当 Client 查询数据时，就不得不查询多个 Region。这样性能自然会有所下降，尤其当 Region 夸机器的时候。因此在大多数的情况下，一个表格不会超过 2 到 3 个 CF，而且很多情况下都是 1 个 CF 就足够了。</p>
<h3 id="Phoenix-的使用">Phoenix 的使用</h3>
<p>当一个新业务需要使用 HBase 时，是完全可以使用 Java API 开发 HBase 的应用，从而实现具体的业务逻辑。但是如果对于习惯使用 RDBMS 的 SQL，或者想要将原来使用 JDBC 的应用直接迁移到 HBase，这就是不可能的。由于这种缅怀过去的情怀，便催生了 Phoenix 的诞生。那么 Phoenix 都能提供哪些功能呢？简单来说 Phoenix 在 HBase 之上提供了 OLTP 相关的功能，例如完全的 ACID 支持、SQL、二级索引等，此外 Phoenix 还提供了标准的 JDBC 的 API。在 Phoenix 的帮助下，RDBMS 的用户可以很容易的使用 HBase，并且迁移原有的业务到 HBase 之中。下来就让我们简单了解一下，如何在 HBase 之上使用 Phoenix。</p>
<p>首先我们需要在 Phoenix 的网站下载与 HBase 版本对应的 Phoenix 安装包。我环境的 HBase 是通过 Ambari HDP2.4 部署的，其中的 HBase 是 1.1 的版本，因此我下载的是下图中的 phoenix-4.7.0-HBase-1.1。</p>
<p><strong>图 6. Phoenix 的下载页面</strong></p>
<p><img src="/assets/images/hbase6.webp" alt="图片描述" title="图片描述"></p>
<p>下载之后需要解压 Phoenix 的 tar 包，并将所有的 jar 文件拷贝到每台 Region Server 机器的 $HBASE_HOME/lib 下面，并重启所有的 Region Server。对于 Ambari 部署的 HBase，其 HBASE_HOME 目录便是/usr/hdp/2.4.0.0-169/hbase/lib/,添加 Jar 包到该目录之后，可以直接在 Ambari 的 WEB 中，重启整个 HBase。重启之后，我们便尽可以进入到刚才解压的 Phoenix 目录，进入其子目录 bin。在这个目录中 Phoenix 提供了 <a target="_blank" rel="noopener" href="http://sqlline.py">sqlline.py</a> 脚本。我们可以通过该脚本连接 HBase，并测试相关的 SQL 语句。我们可以在 bin 目录中看到文件 hbase-site.xml，如果需要对 Phoenix 设置相关参数，就需要更改该文件，并将该文件同步给 HBase 中。<a target="_blank" rel="noopener" href="http://Sqlline.py">Sqlline.py</a> 最简单的使用方法，就是直接以 Zookeeper 机器名为参数即可，如下图：</p>
<p><strong>图 7. <a target="_blank" rel="noopener" href="http://Sqlline.py">Sqlline.py</a> 使用示意图</strong></p>
<p><img src="/assets/images/hbase7.webp" alt="图片描述" title="图片描述"></p>
<p>上图中，我们还使用了 <a target="_blank" rel="noopener" href="http://sqlline.py">sqlline.py</a> 支持的 table 命令，该命令可以列出 HBase 中所有的表。这里需要注意 Phoenix 不支持直接显示 HBase Shell（HBase 自带一个 CLI 访问工具，后续文章在介绍）中创建的表格。原因很简单，当在 Phoenix 创建一张表时，Phoenix 是将表进行了重组装。而对 HBase Shell 创建的表 Phoenix 并未进行加工，所以无法直接显示。如果需要将 HBase Shell 中创建的表格关联到 Phoenix 中查看，就需要在 Phoenix 中创建一个视图（View）做关联。例如，我们现在 HBase Shell 中创建了一张表&quot;table1&quot;，并插入了几行数据，如下。</p>
<p>然后我们在 <a target="_blank" rel="noopener" href="http://Sqlline.py">Sqlline.py</a> 的终端中执行&quot;!table&quot;命令，我们发现并没有 table1 这张表。接下来我们执行如下的命令：</p>
<p>然后再使用!table 命令，这时候结果如下：</p>
<p><strong>图 8. Phoenix 执行表查询结果</strong></p>
<p><img src="/assets/images/hbase8.webp" alt="图片描述" title="图片描述"></p>
<p>我们可以看到结果中多了一个 table1 的视图，这样 Phoenix 就将 table1 表的内容关联到了 Phoenix 的视图当中。我们可以使用 select 等语句访问其中的内容，如下：</p>
<p><strong>图 9. Phoenix 执行查询结果</strong></p>
<p><img src="/assets/images/hbase9.webp" alt="图片描述" title="图片描述"></p>
<p>最后我们再回头解释下刚才创建视图的命令。在创建关联的视图时，我们需要确保视图和列的名称与原表的名称完全一致。Phoenix 默认使用大写字母，因此，当 HBase Shell 中使用的是小写，我们便需要使用双引号引用相关的名称。如果原名称是大写，就可以省去双引号。Pk 是我们定义的一个主键名（可以随便定义），这是由于在 HBase Shell 中并没有主键的概念，所以 Row-key 是没有一个名称的。cf1 和 name 加起来用于指向 HBase 中的一个单元格（Cell），示例的命令中我关联了两个单元格（如果你愿意，可以只关联一个）。在安装了 Phoenix 之后，我们应尽量避免直接使用 HBase Shell 来创建表，取而代之的便是直接使用 Phoenix。例如下图中，我使用 Phoenix 创建了一张表 t1，包含了 name 和 age 两个列，并插入了两行数据。具体的命令如下图：</p>
<p><strong>图 10. 如何在 Phoenix 中创建表</strong><br>
<img src="/assets/images/hbase10.webp" alt="图片描述" title="图片描述"></p>
<p>看到这些命令之后，熟悉 SQL 的读者肯定不会觉得陌生。这便是 Phoenix 提供的最重要的功能之一——SQL 的支持。我们可以看到在 Phoenix 中，我们使用了丰富的数据类型，如 INTEGER 和 VARCHAR。这些都是无法直接在 HBase 中使用的。有兴趣的读者可以在 <a target="_blank" rel="noopener" href="http://sqlline.py">sqlline.py</a> 中尝试更多的 SQL 语句。当需要从 <a target="_blank" rel="noopener" href="http://sqlline.py">sqlline.py</a> 退出时，可以执行!quit 命令（可以通过使用!help 查看更多的命令）。退出 <a target="_blank" rel="noopener" href="http://sqlline.py">sqlline.py</a> 之后，让我们在 HBase Shell 中看看 Phoenix 创建的表会是什么样子。如下：</p>
<p>我们可以明显的看到，Phoenix 将如上的数据进行了重组，才形成了图 10 中所展示的样子。到这里，我们就简单的介绍了 Phoenix 简单的用法。需要强调的是，本章所展示的只是 Phoenix 所提供特性的很小一部分。Phoenix 作为一个标准 JDBC API 的支持者，原有建立在 JDBC 之上应用程序可以直接通过 Phoenix 访问 HBase，例如 Squirrel 这样图形化的 SQL 客户端。当然也可以直接在 Java 代码中通过 JDBC 访问 HBase 数据库，而不用使用 HBase 的 Java API 重新开发。想要了解更多 Phoenix 特性的读者，可以从 Apache Phoenix 官方的文档中查看，例如二级索引等。</p>
<h3 id="总结">总结</h3>
<p>对于 HBase 还有很多内容需要介绍，例如使用 Java API 开发应用，快速部署使用（涉及 Ambari 以及 HBase 部署模式）、HBase Shell 以及如何集成 Hive 和 HBase 等。目前 HBase 的应用场景很多，尤其是互联网公司的后台信息存储中，例如淘宝等都在使用 HBase。我相信了解 HBase 之后，可以更好的架构使用大数据解决方案，这里篇幅有限，后续再介绍更多内容。</p>
<h3 id="参考资源">参考资源</h3>
<p><a target="_blank" rel="noopener" href="https://hadoop.apache.org/">Apache Hadoop</a></p>
<p><a target="_blank" rel="noopener" href="https://phoenix.apache.org/">Apache Phoneix</a></p>
<p><a target="_blank" rel="noopener" href="https://hbase.apache.org/">Apache HBase</a></p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="../../../2017/11/16/database/HBase-%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                留言與分享
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a
                            class="link-unstyled"
                            href="../../../2017/11/05/database/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA-Hadoop-2-7-4-Spark-2-2-0-%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA/"
                            aria-label=": 大数据平台搭建 Hadoop-2.7.4 + Spark-2.2.0 快速搭建"
                        >
                            大数据平台搭建 Hadoop-2.7.4 + Spark-2.2.0 快速搭建
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2017-11-05T14:09:42+08:00">
	
		    2017 年 11 月 5 日
    	
    </time>
    
        <span>分類 </span>
        
    <a class="category-link" href="../../../categories/database/">database</a>, <a class="category-link" href="../../../categories/database/hadoop/">hadoop</a>, <a class="category-link" href="../../../categories/database/hadoop/Spark/">Spark</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h2 id="Apache-Spark-简介">Apache Spark 简介</h2>
<p>Apache Spark 是专为大规模数据处理而设计的快速通用的计算引擎。Spark是UC Berkeley AMP lab (加州大学伯克利分校的AMP实验室)所开源的类Hadoop MapReduce的通用并行框架，Spark，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的MapReduce的算法。</p>
<p>Spark 是一种与 Hadoop 相似的开源集群计算环境，但是两者之间还存在一些不同之处，这些有用的不同之处使 Spark 在某些工作负载方面表现得更加优越，换句话说，Spark 启用了内存分布数据集，除了能够提供交互式查询外，它还可以优化迭代工作负载。</p>
<p>Spark 是在 Scala 语言中实现的，它将 Scala 用作其应用程序框架。与 Hadoop 不同，Spark 和 Scala 能够紧密集成，其中的 Scala 可以像操作本地集合对象一样轻松地操作分布式数据集。</p>
<p>尽管创建 Spark 是为了支持分布式数据集上的迭代作业，但是实际上它是对 Hadoop 的补充，可以在 Hadoop 文件系统中并行运行。通过名为 Mesos 的第三方集群框架可以支持此行为。Spark 由加州大学伯克利分校 AMP 实验室 (Algorithms, Machines, and People Lab) 开发，可用来构建大型的、低延迟的数据分析应用程序。</p>
<h2 id="准备工作">准备工作</h2>
<h3 id="环境">环境</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">JDK:1.8  </span><br><span class="line">Spark-2.2.0</span><br><span class="line">Hadoop Release:2.7.4  </span><br><span class="line">centos:7.3  </span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>主机名</th>
<th>ip地址</th>
<th>安装服务</th>
</tr>
</thead>
<tbody>
<tr>
<td>spark-master</td>
<td>192.168.252.121</td>
<td>jdk、hadoop、spark、scala</td>
</tr>
<tr>
<td>spark-slave01</td>
<td>192.168.252.122</td>
<td>jdk、hadoop、spark</td>
</tr>
<tr>
<td>spark-slave02</td>
<td>192.168.252.123</td>
<td>jdk、hadoop、spark</td>
</tr>
</tbody>
</table>
<h3 id="依赖环境">依赖环境</h3>
<p>Spark 是在 Scala 语言中实现的，它将 Scala 用作其应用程序框架。与 Hadoop 不同，Spark 和 Scala 能够紧密集成，其中的 Scala 可以像操作本地集合对象一样轻松地操作分布式数据集。所有我们安装 Scala</p>
<p><strong>Scala</strong></p>
<p><a href="https://chankein.github.io/2017/06/17/database/Scala-2-13-0-%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE/">Scala-2.13.0 安装及配置</a></p>
<p><strong>Hadoop</strong></p>
<p><a href="https://chankein.github.io/2017/06/16/database/Hadoop-2-7-4-%E9%9B%86%E7%BE%A4%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA/">Hadoop-2.7.4 集群快速搭建</a></p>
<h2 id="安装">安装</h2>
<h3 id="下载解压">下载解压</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">su hadoop</span><br><span class="line">cd /home/hadoop/</span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/apache/spark/spark-2.2.0/spark-2.2.0-bin-hadoop2.7.tgz</span><br><span class="line">tar -zxvf spark-2.2.0-bin-hadoop2.7.tgz</span><br><span class="line">mv spark-2.2.0-bin-hadoop2.7 spark-2.2.0</span><br></pre></td></tr></table></figure>
<h3 id="环境变量">环境变量</h3>
<p>如果是对所有的用户都生效就修改<code>vi /etc/profile</code> 文件<br>
如果只针对当前用户生效就修改 <code>vi ~/.bahsrc</code> 文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/profile</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#spark</span><br><span class="line">export PATH=$&#123;SPARK_HOME&#125;/bin:$PATH</span><br><span class="line">export SPARK_HOME=/home/hadoop/spark-2.2.0/</span><br></pre></td></tr></table></figure>
<p>使环境变量生效，运行 <code>source /etc/profile</code>使<code>/etc/profile</code>文件生效</p>
<h3 id="修改配置">修改配置</h3>
<h4 id="修改-spark-env-sh">修改 <a target="_blank" rel="noopener" href="http://spark-env.sh">spark-env.sh</a></h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop/spark-2.2.0/conf</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mv spark-env.sh.template spark-env.sh</span><br><span class="line">vi spark-env.sh</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#java</span><br><span class="line">export JAVA_HOME=/lib/jvm</span><br><span class="line"></span><br><span class="line">#Spark主节点的IP</span><br><span class="line">export SPARK_MASTER_IP=192.168.252.121</span><br><span class="line"></span><br><span class="line">#Spark主节点的端口号</span><br><span class="line">export SPARK_MASTER_PORT=7077</span><br></pre></td></tr></table></figure>
<p>简单介绍几个变量</p>
<ul>
<li>JAVA_HOME：Java安装目录</li>
<li>SCALA_HOME：Scala安装目录</li>
<li>HADOOP_HOME：hadoop安装目录</li>
<li>HADOOP_CONF_DIR：hadoop集群的配置文件的目录</li>
<li>SPARK_MASTER_IP：spark集群的Master节点的ip地址</li>
<li>SPARK_WORKER_MEMORY：每个worker节点能够最大分配给exectors的内存大小</li>
<li>SPARK_WORKER_CORES：每个worker节点所占有的CPU核数目</li>
<li>SPARK_WORKER_INSTANCES：每台机器上开启的worker节点的数目</li>
</ul>
<h4 id="修改-slaves">修改 slaves</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop/spark-2.2.0/conf</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mv slaves.template slaves</span><br><span class="line">vi slaves</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node1</span><br><span class="line">node2</span><br><span class="line">node3</span><br></pre></td></tr></table></figure>
<h3 id="配置集群">配置集群</h3>
<h4 id="复制节点">复制节点</h4>
<p>进去 spark 安装目录 ，打包，并发送，到其他节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd cd /home/hadoop/</span><br><span class="line"></span><br><span class="line">tar zcvf spark.tar.gz spark-2.2.0</span><br><span class="line"></span><br><span class="line">scp spark.tar.gz hadoop@node2:/home/hadoop/</span><br><span class="line">scp spark.tar.gz hadoop@node3:/home/hadoop/</span><br></pre></td></tr></table></figure>
<p>进去 <code>node1</code>,<code>node2</code> 节点 解压</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop/</span><br><span class="line"></span><br><span class="line">tar -zxvf spark.tar.gz</span><br></pre></td></tr></table></figure>
<h4 id="环境变量-2">环境变量</h4>
<p><strong>到这里一步 确保你的每一个节点 环境变量够数</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#jdk</span><br><span class="line">export JAVA_HOME=/lib/jvm</span><br><span class="line">export JRE_HOME=$&#123;JAVA_HOME&#125;/jre</span><br><span class="line">export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib</span><br><span class="line">export PATH=$&#123;SPARK_HOME&#125;/bin:$&#123;SCALA_HOME&#125;/bin:$&#123;HADOOP_HOME&#125;/bin:$&#123;JAVA_HOME&#125;/bin:$PATH</span><br><span class="line"></span><br><span class="line">#hadoop</span><br><span class="line">export HADOOP_HOME=/home/hadoop/hadoop-2.7.4/</span><br><span class="line"></span><br><span class="line">#scala</span><br><span class="line">export SCALA_HOME=/lib/scala</span><br><span class="line"></span><br><span class="line">#spark</span><br><span class="line">export SPARK_HOME=/home/hadoop/spark-2.2.0/</span><br></pre></td></tr></table></figure>
<h3 id="启动集群">启动集群</h3>
<p>关闭防火墙</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld.service</span><br></pre></td></tr></table></figure>
<h4 id="启动-Hadoop">启动 Hadoop</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop/hadoop-2.7.4/sbin</span><br><span class="line"></span><br><span class="line">./start-all.sh</span><br></pre></td></tr></table></figure>
<h4 id="启动-Spark">启动 Spark</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop/spark-2.2.0/sbin</span><br><span class="line"></span><br><span class="line">./start-all.sh</span><br></pre></td></tr></table></figure>
<h4 id="启动-Spark-Shell">启动 Spark Shell</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop/spark-2.2.0/bin</span><br><span class="line"></span><br><span class="line">./spark-shell</span><br></pre></td></tr></table></figure>
<p>spark 访问：192.168.252.121:8080</p>
<p>spark-shell 访问：192.168.252.121:4040</p>
<p><img src="/assets/images/spark1.webp" alt="图片描述" title="图片描述"></p>
<p><img src="/assets/images/spark2.webp" alt="图片描述" title="图片描述"></p>

                    
                        


                    
                    
                        <p>
                            <a
                                href="../../../2017/11/05/database/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA-Hadoop-2-7-4-Spark-2-2-0-%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA/#post-footer"
                                class="postShorten-excerpt_link link"
                                aria-label=""
                            >
                                留言與分享
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    <div class="pagination-bar">
    <ul class="pagination">
        
        
        <li class="pagination-number">第 1 頁 共 1 頁</li>
    </ul>
</div>

</section>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2025 Kein Chan. All Rights Reserved.
    </span>
</footer>

            </div>
            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="../../../assets/images/profile.jpg" alt="作者的圖片"/>
        
            <h4 id="about-card-name">Kein Chan</h4>
        
            <div id="about-card-bio"><p>這是獨立全棧工程師Kein Chan的技術博客</br>分享一些技術教程,命令備忘(cheat-sheet)等</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>全棧工程師</br>資深技術顧問</br>數據科學家</br>Hit廣島觀光大使</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                Tokyo/Macau
            </div>
        
    </div>
</div>

        
            <div id="algolia-search-modal" class="modal-container">
    <div class="modal">
        <div class="modal-header">
            <span class="close-button"><i class="fa fa-times"></i></span>
            <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
                <span class="searchby-algolia-text text-color-light text-small">by</span>
                <img class="searchby-algolia-logo" src="../assets/images/logo-algolia-nebula-blue-full.svg">
            </a>
            <i class="search-icon fa fa-search"></i>
            <form id="algolia-search-form">
                <input type="text" id="algolia-search-input" name="search"
                    class="form-control input--large search-input" placeholder="Search "
                    />
            </form>
        </div>
        <div class="modal-body">
            <div class="no-result text-color-light text-center">沒有找到文章</div>
            <div class="results">
                
                <div class="media">
                    
                    <div class="media-body">
                        <a
                            class="link-unstyled"
                            href="https://chankein.github.io/2013/04/27/R%E8%AF%AD%E8%A8%80/R%E8%AF%AD%E8%A8%80-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"
                            aria-label=": R语言-环境安装"
                        >
                            <h3 class="media-heading">R语言-环境安装</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    2013年4月27日
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a
                            class="link-unstyled"
                            href="https://chankein.github.io/2013/04/28/R%E8%AF%AD%E8%A8%80/R%E8%AF%AD%E8%A8%80-%E5%9F%BA%E7%A1%80/"
                            aria-label=": R语言-基础"
                        >
                            <h3 class="media-heading">R语言-基础</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    2013年4月28日
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a
                            class="link-unstyled"
                            href="https://chankein.github.io/2013/05/01/R%E8%AF%AD%E8%A8%80/R%E8%AF%AD%E8%A8%80-%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE/"
                            aria-label=": R语言-读取数据"
                        >
                            <h3 class="media-heading">R语言-读取数据</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    2013年5月1日
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a
                            class="link-unstyled"
                            href="https://chankein.github.io/2013/05/02/R%E8%AF%AD%E8%A8%80/R%E8%AF%AD%E8%A8%80-%E7%BB%98%E5%9B%BE/"
                            aria-label=": R语言-绘图"
                        >
                            <h3 class="media-heading">R语言-绘图</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    2013年5月2日
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a
                            class="link-unstyled"
                            href="https://chankein.github.io/2013/05/03/R%E8%AF%AD%E8%A8%80/R%E8%AF%AD%E8%A8%80-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"
                            aria-label=": R语言-线性回归"
                        >
                            <h3 class="media-heading">R语言-线性回归</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    2013年5月3日
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a
                            class="link-unstyled"
                            href="https://chankein.github.io/2015/02/22/Algorithms/1.%E7%AE%97%E6%B3%95%E5%9C%A8%E8%AE%A1%E7%AE%97%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8/"
                            aria-label=": 1. 算法在计算中的作用"
                        >
                            <h3 class="media-heading">1. 算法在计算中的作用</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    2015年2月22日
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a
                            class="link-unstyled"
                            href="https://chankein.github.io/2015/02/23/Algorithms/2.%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/"
                            aria-label=": 2. 算法基础"
                        >
                            <h3 class="media-heading">2. 算法基础</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    2015年2月23日
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a
                            class="link-unstyled"
                            href="https://chankein.github.io/2015/02/24/Algorithms/3.%E5%87%BD%E6%95%B0%E7%9A%84%E5%A2%9E%E9%95%BF/"
                            aria-label=": 3. 函数的增长"
                        >
                            <h3 class="media-heading">3. 函数的增长</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    2015年2月24日
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a
                            class="link-unstyled"
                            href="https://chankein.github.io/2015/02/25/Algorithms/4.%E5%88%86%E6%B2%BB%E7%AD%96%E7%95%A5/"
                            aria-label=": 4. 分治策略"
                        >
                            <h3 class="media-heading">4. 分治策略</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    2015年2月25日
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a
                            class="link-unstyled"
                            href="https://chankein.github.io/2015/02/26/Algorithms/5.%E6%A6%82%E7%8E%87%E5%88%86%E6%9E%90%E5%92%8C%E9%9A%8F%E6%9C%BA%E7%AE%97%E6%B3%95/"
                            aria-label=": 5. 概率分析和随机算法"
                        >
                            <h3 class="media-heading">5. 概率分析和随机算法</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    2015年2月26日
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
            </div>
        </div>
        <div class="modal-footer">
            <p class="results-count text-medium"
                data-message-zero="沒有找到文章"
                data-message-one="找到 1 篇文章"
                data-message-other="找到 {n} 篇文章">
                找到 235 篇文章
            </p>
        </div>
    </div>
</div>

        
        
<div id="cover" style="background-image:url('../../../assets/images/cover.jpeg');"></div>
        <!--SCRIPTS-->

<script src="../../../assets/js/script-qtzvvb63gamuirvfphht7lytrxkfllzng1escnm2phjtlt4tvvxi5gl0wx4o.min.js"></script>

<!--SCRIPTS END-->





    </body>
</html>
